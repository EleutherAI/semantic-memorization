{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mchorse/miniconda3/envs/memorization/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset, get_dataset_split_names, DatasetDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_color_codes(\"colorblind\")\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_sample_size = None\n",
    "label_title_padding = 10\n",
    "study_pile = False\n",
    "RECITATION_THRESHOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "memories_path = \"usvsnsp/generation-semantic-filters\"\n",
    "intermediate_path = \"usvsnsp/generation-semantic-intermediate-filters\"\n",
    "memories_dataset = DatasetDict()\n",
    "splits = [split for split in get_dataset_split_names(memories_path) if \"deduped\" in split] + get_dataset_split_names(intermediate_path)\n",
    "# drop splits with \"pile\" in the name\n",
    "splits = [split for split in splits if \"pile\" not in split and \"deduped\" in split]\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading datasets...\")\n",
    "print(f\"Split sample size: {split_sample_size}\")\n",
    "\n",
    "for split in tqdm(splits):\n",
    "    model = split.split(\"_\")[-1]\n",
    "    checkpoint = int(split.split(\".\")[-1]) if split.split(\".\")[-1][1].isnumeric() else \"Final\"\n",
    "    formatted_split_name = split.replace(\"memories_\", \"\").replace(\"deduped_\", \"deduped.\")\n",
    "    dataset_path = memories_path if checkpoint == \"Final\" else intermediate_path\n",
    "    memories_dataset[formatted_split_name] = load_dataset(dataset_path, split=f\"{split}[:{split_sample_size}]\" if split_sample_size else split)\n",
    "\n",
    "memories_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_to_param_count = {\n",
    "    \"70m\": 70000000,\n",
    "    \"160m\": 160000000,\n",
    "    \"410m\": 410000000,\n",
    "    \"1b\": 1000000000,\n",
    "    \"1.4b\": 1400000000,\n",
    "    \"2.8b\": 2800000000,\n",
    "    \"6.9b\": 6900000000,\n",
    "    \"12b\": 12000000000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"frequencies\", \"tokens\"]\n",
    "combined_dataframe = None\n",
    "for split in tqdm(memories_dataset, desc=\"Loading Memories\"):\n",
    "    current_frame = memories_dataset[split].to_pandas()\n",
    "    current_frame.drop(columns=columns_to_drop, inplace=True)\n",
    "    checkpoint = int(split.split(\".\")[-1]) if split.split(\".\")[-1][1].isnumeric() and len(split.split(\".\")) != 2 else \"Final\"\n",
    "    current_frame[\"Checkpoint\"] = checkpoint\n",
    "    model = split.split(\"deduped\")[-1][1:] if checkpoint == \"Final\" else split.split(\".\")[-2]\n",
    "    print(f\"Model: {model} from {split}\")\n",
    "    current_frame[\"Model\"] = model\n",
    "    current_frame[\"Param Count\"] = split_to_param_count[current_frame[\"Model\"].iloc[0]]\n",
    "    current_frame[\"Deduped\"] = \"deduped\" in split\n",
    "    current_frame[\"Memorized\"] = True\n",
    "    if combined_dataframe is None:\n",
    "        combined_dataframe = current_frame\n",
    "    else:\n",
    "        combined_dataframe = pd.concat([combined_dataframe, current_frame])\n",
    "\n",
    "combined_dataframe = combined_dataframe.sort_values(\"Param Count\")\n",
    "display(combined_dataframe.shape)\n",
    "display(combined_dataframe.columns)\n",
    "combined_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure: Perplexity and Duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line plot where sequence_duplicates is the x axis and the y axis is the generation_perplexity\n",
    "deduped_12b = combined_dataframe[(combined_dataframe[\"Model\"] == \"12b\") & (combined_dataframe[\"Checkpoint\"] == \"Final\") & (combined_dataframe[\"Deduped\"] == True)]\n",
    "\n",
    "deduped_12b = deduped_12b[deduped_12b[\"sequence_duplicates\"] <= 1000]\n",
    "\n",
    "display(deduped_12b.shape)\n",
    "\n",
    "# bucket the sequence_duplicates by 5\n",
    "# deduped_12b[\"sequence_duplicates\"] = deduped_12b[\"sequence_duplicates\"].apply(lambda x: x - (x % 5))\n",
    "\n",
    "sns.lineplot(data=deduped_12b, x=\"sequence_duplicates\", y=\"generation_perplexity\")\n",
    "\n",
    "# y label is \"Perplexity\" and x label is \"Duplicates\"\n",
    "plt.xlabel(\"Duplicates\", labelpad=label_title_padding)\n",
    "plt.ylabel(\"Perplexity\", labelpad=label_title_padding)\n",
    "\n",
    "# set figure dimensions\n",
    "plt.gcf().set_size_inches(13, 3)\n",
    "\n",
    "# log x axis\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "# log y axis\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and std dev for each bucket\n",
    "duplication_ppl_stats = deduped_12b.groupby(\"sequence_duplicates\").agg({\"generation_perplexity\": [\"mean\", \"std\"]})\n",
    "display(duplication_ppl_stats)\n",
    "duplication_ppl_stats.to_csv(\"duplication_ppl_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Examples to Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(row):\n",
    "    if row[\"Memorized\"] == False:\n",
    "        return \"Not Memorized\"\n",
    "    if row[\"sequence_duplicates\"] >= RECITATION_THRESHOLD:\n",
    "        return \"Recitation\"\n",
    "    if row[\"is_incrementing\"] or row[\"is_repeating\"]:\n",
    "        return \"Reconstruction\"\n",
    "\n",
    "    return \"Recollection\"\n",
    "\n",
    "combined_dataframe[\"category\"] = combined_dataframe.progress_apply(lambda row: get_category(row), axis=1)\n",
    "combined_dataframe.value_counts([\"Model\", \"Checkpoint\", \"category\"])\n",
    "\n",
    "# 12 deduped\n",
    "# memories_frame = combined_dataframe[(combined_dataframe[\"Memorized\"] == True) & (combined_dataframe[\"Deduped\"] == True) & (combined_dataframe[\"Model\"] == \"12b\")]\n",
    "# memories_frame[\"category\"] = memories_frame.progress_apply(lambda row: get_category(row), axis=1)\n",
    "# memories_frame.value_counts(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure: Prevalence and Memories by Taxonomy Across Time and Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot for data across \n",
    "final_checkpoint_counts_frame = combined_dataframe[combined_dataframe[\"Checkpoint\"] == \"Final\"].value_counts([\"Param Count\", \"category\"]).unstack().reindex(split_to_param_count.values())\n",
    "final_checkpoint_counts_frame.to_csv(f\"final_checkpoint_counts_recitation={RECITATION_THRESHOLD}.csv\")\n",
    "display(final_checkpoint_counts_frame)\n",
    "\n",
    "intermediate_frame = combined_dataframe[(combined_dataframe[\"Checkpoint\"] != \"Final\") & (combined_dataframe[\"Model\"] == \"12b\")]\n",
    "sorted_checkpoints = sorted(intermediate_frame[\"Checkpoint\"].unique(), key=lambda x: int(x))\n",
    "\n",
    "intermediate_checkpoint_counts_frame = intermediate_frame.value_counts([\"Checkpoint\", \"category\"]).unstack().reindex(sorted_checkpoints)\n",
    "intermediate_checkpoint_counts_frame.to_csv(f\"intermediate_checkpoint_counts_recitation={RECITATION_THRESHOLD}.csv\")\n",
    "display(intermediate_checkpoint_counts_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 3))\n",
    "\n",
    "# set figure 1\n",
    "# first figure is a line plot of the counts of each category for across intermediate checkpoints\n",
    "\n",
    "sns.lineplot(ax=axes[0], data=intermediate_checkpoint_counts_frame, dashes=False, markers=True, markersize=8)\n",
    "\n",
    "# rotate x axis labels\n",
    "# axes[0].tick_params(axis='x', rotation=20)\n",
    "\n",
    "# make x labels smaller\n",
    "axes[0].tick_params(axis='x', labelsize=12)\n",
    "\n",
    "# Add y label for Count\n",
    "axes[0].set_ylabel(\"Count\", labelpad=label_title_padding)\n",
    "\n",
    "# add padding for labels\n",
    "fig.subplots_adjust(wspace=0.2)\n",
    "\n",
    "# # make x axis log scale\n",
    "# axes[0].set_xscale(\"log\")\n",
    "\n",
    "# # have a common legend for both plots centered below the figure. No legend box\n",
    "axes[0].legend(loc='upper center', bbox_to_anchor=(1.1, -0.3), ncol=4, frameon=False)\n",
    "\n",
    "# set figure 2\n",
    "# the second figure is a line plot of the counts of each category across parameter count\n",
    "\n",
    "sns.lineplot(ax=axes[1], data=final_checkpoint_counts_frame, dashes=False, markers=True, markersize=8)\n",
    "\n",
    "# make x axis log scale\n",
    "axes[1].set_xscale(\"log\")\n",
    "\n",
    "# Set x label to \"Parameters\"\n",
    "axes[1].set_xlabel(\"Parameters\")\n",
    "\n",
    "# Add y label for Count\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "\n",
    "# remove legend\n",
    "axes[1].legend().remove()\n",
    "\n",
    "# add padding for labels\n",
    "fig.subplots_adjust(wspace=0.30)\n",
    "\n",
    "fig.savefig(f\"categories_across_time+scale_recitation={RECITATION_THRESHOLD}.png\", bbox_inches=\"tight\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure: Prevalence and Percents of Memories by Taxonomy Across Param Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_frame = combined_dataframe.value_counts([\"Param Count\", \"category\"]).unstack().reindex(split_to_param_count.values())\n",
    "display(counts_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_checkpoints = [23000, 43000, 63000, 83000, 103000, 123000]\n",
    "assert len(sorted_checkpoints) + 1 == len(combined_dataframe[(combined_dataframe[\"Model\"] == \"12b\") & (combined_dataframe[\"Deduped\"] == True)][\"Checkpoint\"].unique())\n",
    "\n",
    "all_percents_time = []\n",
    "for checkpoint in tqdm(sorted_checkpoints):\n",
    "    model_examples = combined_dataframe[combined_dataframe[\"Checkpoint\"] == checkpoint]\n",
    "    model_percents = model_examples.value_counts(\"category\", normalize=True).to_dict()\n",
    "    for category in model_percents:\n",
    "        all_percents_time.append({\n",
    "            \"Checkpoint\": checkpoint,\n",
    "            \"category\": category,\n",
    "            \"percent\": model_percents[category],\n",
    "        })\n",
    "\n",
    "percents_frame_time = pd.DataFrame(all_percents_time).pivot(index=\"Checkpoint\", columns=\"category\", values=\"percent\").reindex(sorted_checkpoints)\n",
    "percents_frame_time.to_csv(f\"percents_frame_time_recitation={RECITATION_THRESHOLD}.csv\")\n",
    "display(percents_frame_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_percents_scale = []\n",
    "for param_count in tqdm(split_to_param_count.values()):\n",
    "    model_examples = combined_dataframe[combined_dataframe[\"Param Count\"] == param_count]\n",
    "    model_percents = model_examples.value_counts(\"category\", normalize=True).to_dict()\n",
    "    for category in model_percents:\n",
    "        all_percents_scale.append({\n",
    "            \"Model\": model_examples[\"Model\"].unique()[0],\n",
    "            \"Param Count\": param_count,\n",
    "            \"category\": category,\n",
    "            \"percent\": model_percents[category],\n",
    "        })\n",
    "\n",
    "percents_frame_scale = pd.DataFrame(all_percents_scale).pivot(index=\"Model\", columns=\"category\", values=\"percent\").reindex(split_to_param_count.keys())\n",
    "percents_frame_scale.to_csv(f\"percents_frame_scale_recitation={RECITATION_THRESHOLD}.csv\")\n",
    "display(percents_frame_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 3))\n",
    "plots = [\n",
    "    (percents_frame_time, axes[0]),\n",
    "    (percents_frame_scale, axes[1])\n",
    "]\n",
    "\n",
    "for idx, (data, ax) in enumerate(plots):\n",
    "    data.plot.bar(\n",
    "        stacked=True,\n",
    "        ax=ax,\n",
    "        rot=0,\n",
    "        width=1,\n",
    "        ylabel=\"Memories\",\n",
    "    )\n",
    "\n",
    "    if idx == 0:\n",
    "        ax.set_xlabel(\"Checkpoint\")\n",
    "    else:\n",
    "        ax.set_xlabel(\"Parameter Count\")\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}%\".format(int(x * 100))))\n",
    "    ax.tick_params(axis='x', rotation=20, labelsize=12)\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "# Adjusting subplot parameters\n",
    "fig.subplots_adjust(wspace=0.30)\n",
    "\n",
    "# Common legend configuration\n",
    "axes[0].legend(loc='upper center', bbox_to_anchor=(1.1, -0.4), ncol=4, frameon=False)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"figure_categories_count_percents.png\", bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memorization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
