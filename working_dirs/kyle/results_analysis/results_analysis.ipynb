{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset, get_dataset_split_names, DatasetDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_sample_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--memories-semantic-memorization-filter-results-7ad10bc8c7f6aa70/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      " 12%|█▎        | 1/8 [00:00<00:03,  1.96it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--memories-semantic-memorization-filter-results-7ad10bc8c7f6aa70/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      " 25%|██▌       | 2/8 [00:01<00:03,  1.87it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--memories-semantic-memorization-filter-results-7ad10bc8c7f6aa70/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      " 38%|███▊      | 3/8 [00:01<00:02,  1.93it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--memories-semantic-memorization-filter-results-7ad10bc8c7f6aa70/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      " 50%|█████     | 4/8 [00:02<00:02,  1.84it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--memories-semantic-memorization-filter-results-7ad10bc8c7f6aa70/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      " 62%|██████▎   | 5/8 [00:02<00:01,  1.93it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--memories-semantic-memorization-filter-results-7ad10bc8c7f6aa70/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      " 75%|███████▌  | 6/8 [00:03<00:00,  2.02it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--memories-semantic-memorization-filter-results-7ad10bc8c7f6aa70/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      " 88%|████████▊ | 7/8 [00:03<00:00,  2.10it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--memories-semantic-memorization-filter-results-7ad10bc8c7f6aa70/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 8/8 [00:03<00:00,  2.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    memories.deduped.1.4b: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    memories.deduped.12b: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    memories.deduped.160m: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    memories.deduped.1b: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    memories.deduped.2.8b: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    memories.deduped.410m: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    memories.deduped.6.9b: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    memories.deduped.70m: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories_path = \"usvsnsp/memories-semantic-memorization-filter-results\"\n",
    "get_dataset_split_names(memories_path)\n",
    "memories_dataset = DatasetDict()\n",
    "\n",
    "# get splits that have deduped in the name\n",
    "splits = [split for split in get_dataset_split_names(memories_path) if \"deduped\" in split]\n",
    "for split in tqdm(splits):\n",
    "    memories_dataset[split] = load_dataset(memories_path, split=f\"{split}[:{split_sample_size}]\" if split_sample_size else split)\n",
    "\n",
    "memories_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--pile-semantic-memorization-filter-results-e8ad7274ba998093/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      " 12%|█▎        | 1/8 [00:00<00:03,  1.98it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--pile-semantic-memorization-filter-results-e8ad7274ba998093/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      " 25%|██▌       | 2/8 [00:01<00:03,  1.68it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--pile-semantic-memorization-filter-results-e8ad7274ba998093/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      " 38%|███▊      | 3/8 [00:01<00:02,  1.83it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--pile-semantic-memorization-filter-results-e8ad7274ba998093/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      " 50%|█████     | 4/8 [00:02<00:02,  1.82it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--pile-semantic-memorization-filter-results-e8ad7274ba998093/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      " 62%|██████▎   | 5/8 [00:02<00:01,  1.80it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--pile-semantic-memorization-filter-results-e8ad7274ba998093/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      " 75%|███████▌  | 6/8 [00:03<00:01,  1.87it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--pile-semantic-memorization-filter-results-e8ad7274ba998093/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      " 88%|████████▊ | 7/8 [00:03<00:00,  1.91it/s]Found cached dataset parquet (/home/kyle/.cache/huggingface/datasets/usvsnsp___parquet/usvsnsp--pile-semantic-memorization-filter-results-e8ad7274ba998093/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    pile.deduped.1.4b: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    pile.deduped.12b: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    pile.deduped.160m: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    pile.deduped.1b: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    pile.deduped.2.8b: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    pile.deduped.410m: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    pile.deduped.6.9b: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    pile.deduped.70m: Dataset({\n",
       "        features: ['sequence_id', 'text', 'sequence_duplicates', 'max_frequency', 'avg_frequency', 'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency', 'frequencies', 'is_incrementing', 'tokens', 'repeating_offset', 'num_repeating', 'smallest_repeating_chunk', 'memorization_score', 'templating_frequency_0.9', 'templating_frequency_0.8', 'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pile_path = \"usvsnsp/pile-semantic-memorization-filter-results\"\n",
    "get_dataset_split_names(pile_path)\n",
    "pile_dataset = DatasetDict()\n",
    "\n",
    "splits = [split for split in get_dataset_split_names(pile_path) if \"deduped\" in split]\n",
    "for split in tqdm(splits):\n",
    "    pile_dataset[split] = load_dataset(pile_path, split=f\"{split}[:{split_sample_size}]\" if split_sample_size else split)\n",
    "\n",
    "pile_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_to_param_count = {\n",
    "    \"70m\": 70000000,\n",
    "    \"160m\": 160000000,\n",
    "    \"410m\": 410000000,\n",
    "    \"1b\": 1000000000,\n",
    "    \"1.4b\": 1400000000,\n",
    "    \"2.8b\": 2800000000,\n",
    "    \"6.9b\": 6900000000,\n",
    "    \"12b\": 12000000000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Memories: 100%|██████████| 8/8 [00:00<00:00, 30.43it/s]\n",
      "Loading Pile: 100%|██████████| 8/8 [00:00<00:00, 30.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(160000, 22)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_duplicates</th>\n",
       "      <th>max_frequency</th>\n",
       "      <th>avg_frequency</th>\n",
       "      <th>min_frequency</th>\n",
       "      <th>median_frequency</th>\n",
       "      <th>p25_frequency</th>\n",
       "      <th>p75_frequency</th>\n",
       "      <th>is_incrementing</th>\n",
       "      <th>repeating_offset</th>\n",
       "      <th>...</th>\n",
       "      <th>memorization_score</th>\n",
       "      <th>templating_frequency_0.9</th>\n",
       "      <th>templating_frequency_0.8</th>\n",
       "      <th>prompt_perplexity</th>\n",
       "      <th>generation_perplexity</th>\n",
       "      <th>sequence_perplexity</th>\n",
       "      <th>Model</th>\n",
       "      <th>Param Count</th>\n",
       "      <th>Deduped</th>\n",
       "      <th>Memorized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21590</td>\n",
       "      <td>55</td>\n",
       "      <td>11740996961</td>\n",
       "      <td>9.379041e+08</td>\n",
       "      <td>3053059</td>\n",
       "      <td>277329702.0</td>\n",
       "      <td>20962725</td>\n",
       "      <td>395603541</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>130</td>\n",
       "      <td>1.598633</td>\n",
       "      <td>1.002930</td>\n",
       "      <td>1.603516</td>\n",
       "      <td>1.4b</td>\n",
       "      <td>1400000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30252</td>\n",
       "      <td>21482</td>\n",
       "      <td>10346382453</td>\n",
       "      <td>2.780063e+09</td>\n",
       "      <td>1869557</td>\n",
       "      <td>385281005.0</td>\n",
       "      <td>13592032</td>\n",
       "      <td>695610999</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>696</td>\n",
       "      <td>2333</td>\n",
       "      <td>1.178711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.178711</td>\n",
       "      <td>1.4b</td>\n",
       "      <td>1400000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35232</td>\n",
       "      <td>21829</td>\n",
       "      <td>11740996961</td>\n",
       "      <td>2.526616e+09</td>\n",
       "      <td>860666</td>\n",
       "      <td>42752068.5</td>\n",
       "      <td>6514834</td>\n",
       "      <td>1502731047</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116</td>\n",
       "      <td>389</td>\n",
       "      <td>1.164062</td>\n",
       "      <td>1.013672</td>\n",
       "      <td>1.178711</td>\n",
       "      <td>1.4b</td>\n",
       "      <td>1400000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62350</td>\n",
       "      <td>10</td>\n",
       "      <td>9362638615</td>\n",
       "      <td>8.393529e+08</td>\n",
       "      <td>397964</td>\n",
       "      <td>16284663.0</td>\n",
       "      <td>4176692</td>\n",
       "      <td>918861018</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.933594</td>\n",
       "      <td>1.035156</td>\n",
       "      <td>2.001953</td>\n",
       "      <td>1.4b</td>\n",
       "      <td>1400000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75902</td>\n",
       "      <td>1</td>\n",
       "      <td>11740996961</td>\n",
       "      <td>9.808267e+08</td>\n",
       "      <td>783155</td>\n",
       "      <td>216143855.5</td>\n",
       "      <td>43385287</td>\n",
       "      <td>909893795</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>329</td>\n",
       "      <td>1.779297</td>\n",
       "      <td>1.005859</td>\n",
       "      <td>1.791016</td>\n",
       "      <td>1.4b</td>\n",
       "      <td>1400000000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id  sequence_duplicates  max_frequency  avg_frequency   \n",
       "0        21590                   55    11740996961   9.379041e+08  \\\n",
       "1        30252                21482    10346382453   2.780063e+09   \n",
       "2        35232                21829    11740996961   2.526616e+09   \n",
       "3        62350                   10     9362638615   8.393529e+08   \n",
       "4        75902                    1    11740996961   9.808267e+08   \n",
       "\n",
       "   min_frequency  median_frequency  p25_frequency  p75_frequency   \n",
       "0        3053059       277329702.0       20962725      395603541  \\\n",
       "1        1869557       385281005.0       13592032      695610999   \n",
       "2         860666        42752068.5        6514834     1502731047   \n",
       "3         397964        16284663.0        4176692      918861018   \n",
       "4         783155       216143855.5       43385287      909893795   \n",
       "\n",
       "   is_incrementing  repeating_offset  ...  memorization_score   \n",
       "0             True                 0  ...                 1.0  \\\n",
       "1             True                 0  ...                 1.0   \n",
       "2            False                 0  ...                 1.0   \n",
       "3            False                 0  ...                 1.0   \n",
       "4            False                 0  ...                 1.0   \n",
       "\n",
       "  templating_frequency_0.9  templating_frequency_0.8  prompt_perplexity   \n",
       "0                       22                       130           1.598633  \\\n",
       "1                      696                      2333           1.178711   \n",
       "2                      116                       389           1.164062   \n",
       "3                        1                         1           1.933594   \n",
       "4                       18                       329           1.779297   \n",
       "\n",
       "   generation_perplexity  sequence_perplexity  Model  Param Count Deduped   \n",
       "0               1.002930             1.603516   1.4b   1400000000    True  \\\n",
       "1               1.000000             1.178711   1.4b   1400000000    True   \n",
       "2               1.013672             1.178711   1.4b   1400000000    True   \n",
       "3               1.035156             2.001953   1.4b   1400000000    True   \n",
       "4               1.005859             1.791016   1.4b   1400000000    True   \n",
       "\n",
       "   Memorized  \n",
       "0       True  \n",
       "1       True  \n",
       "2       True  \n",
       "3       True  \n",
       "4       True  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataframe = None\n",
    "for split in tqdm(memories_dataset, desc=\"Loading Memories\"):\n",
    "    current_frame = memories_dataset[split].to_pandas()\n",
    "    current_frame.drop(columns=[\"text\", \"frequencies\", \"tokens\"], inplace=True)\n",
    "    current_frame[\"Model\"] = \".\".join(split.split(\".\")[2:])\n",
    "    current_frame[\"Param Count\"] = split_to_param_count[current_frame[\"Model\"].iloc[0]]\n",
    "    current_frame[\"Deduped\"] = \"deduped\" in split\n",
    "    current_frame[\"Memorized\"] = True\n",
    "    if combined_dataframe is None:\n",
    "        combined_dataframe = current_frame\n",
    "    else:\n",
    "        combined_dataframe = pd.concat([combined_dataframe, current_frame])\n",
    "\n",
    "for split in tqdm(pile_dataset, desc=\"Loading Pile\"):\n",
    "    current_frame = pile_dataset[split].to_pandas()\n",
    "    current_frame.drop(columns=[\"text\", \"frequencies\", \"tokens\"], inplace=True)\n",
    "    current_frame[\"Model\"] = \".\".join(split.split(\".\")[2:])\n",
    "    current_frame[\"Param Count\"] = split_to_param_count[current_frame[\"Model\"].iloc[0]]\n",
    "    current_frame[\"Deduped\"] = \"deduped\" in split\n",
    "    current_frame[\"Memorized\"] = False\n",
    "    combined_dataframe = pd.concat([combined_dataframe, current_frame])\n",
    "\n",
    "display(combined_dataframe.shape)\n",
    "combined_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 13 rows with -1 generation_perplexity\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "num_repeating\n",
       "0     154873\n",
       "2       1093\n",
       "4        754\n",
       "32       497\n",
       "6        418\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# drop cases where generation_perplexity is -1\n",
    "before_count = combined_dataframe.shape[0]\n",
    "combined_dataframe = combined_dataframe[combined_dataframe[\"generation_perplexity\"] != -1]\n",
    "after_count = combined_dataframe.shape[0]\n",
    "print(f\"Dropped {before_count - after_count} rows with -1 generation_perplexity\")\n",
    "\n",
    "# set num_repeating = 0 if -1\n",
    "combined_dataframe.loc[combined_dataframe[\"num_repeating\"] == -1, \"num_repeating\"] = 0\n",
    "display(combined_dataframe.value_counts(\"num_repeating\").head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Examples to Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159987/159987 [00:01<00:00, 90960.90it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "Not Memorized     80000\n",
       "Reconstruction    47014\n",
       "Recitation        32973\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_category(row):\n",
    "    if row[\"Memorized\"] == False:\n",
    "        return \"Not Memorized\"\n",
    "    if row[\"sequence_duplicates\"] >= 200:\n",
    "        return \"Recitation\"\n",
    "    if row[\"is_incrementing\"] or row[\"num_repeating\"] != -1:\n",
    "        return \"Reconstruction\"\n",
    "\n",
    "    return \"Recollection\"\n",
    "\n",
    "combined_dataframe[\"category\"] = combined_dataframe.progress_apply(lambda row: get_category(row), axis=1)\n",
    "combined_dataframe.value_counts(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_path = \"usvsnsp/pile-pythia-code-vs-nl-scores\"\n",
    "# code_dataset = load_dataset(code_path)[\"train\"].to_pandas()\n",
    "# code_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Join combined_dataframe with code_dataset on sequence_id\n",
    "# combined_dataframe = combined_dataframe.merge(code_dataset, on=\"sequence_id\", how=\"inner\")\n",
    "# combined_dataframe[\"is_code\"] = combined_dataframe[\"nl_score\"] <= 0.45\n",
    "# display(combined_dataframe.shape)\n",
    "# combined_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box_plot_token_stats = []\n",
    "# for param_count in tqdm(split_to_param_count.values()):\n",
    "#     sub_plots = []\n",
    "#     for is_memorized in [True, False]:\n",
    "#         model_examples = combined_dataframe[(combined_dataframe[\"Param Count\"] == param_count) & (combined_dataframe[\"Memorized\"] == is_memorized)]\n",
    "#         sub_plots.append({\n",
    "#             \"mean\": model_examples[\"avg_frequency\"].mean(),\n",
    "#             \"med\": model_examples[\"median_frequency\"].mean(),\n",
    "#             \"q1\": model_examples[\"p25_frequency\"].mean(),\n",
    "#             \"q3\": model_examples[\"p75_frequency\"].mean(),\n",
    "#             \"whislo\": model_examples[\"min_frequency\"].mean(),\n",
    "#             \"whishi\": model_examples[\"max_frequency\"].mean(),\n",
    "#         })\n",
    "\n",
    "#     box_plot_token_stats.append(sub_plots)\n",
    "\n",
    "# box_plot_token_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 237.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'mean': 1825873775.0383341,\n",
       "  'med': 217947783.51687837,\n",
       "  'q1': 25506369.640428085,\n",
       "  'q3': 1794763340.2740047,\n",
       "  'whislo': 6669234.314462893,\n",
       "  'whishi': 10927637798.817913},\n",
       " {'mean': 1824578740.2041776,\n",
       "  'med': 203097249.5979647,\n",
       "  'q1': 23469151.846376956,\n",
       "  'q3': 1787233613.706706,\n",
       "  'whislo': 5526651.434615192,\n",
       "  'whishi': 10989805343.758564},\n",
       " {'mean': 1811900453.8840518,\n",
       "  'med': 186002567.02240223,\n",
       "  'q1': 20547499.620562058,\n",
       "  'q3': 1782834454.339934,\n",
       "  'whislo': 3538349.2325732573,\n",
       "  'whishi': 10995104127.622612},\n",
       " {'mean': 1802332541.0913756,\n",
       "  'med': 174383212.50712535,\n",
       "  'q1': 19302464.214660734,\n",
       "  'q3': 1755750327.5931296,\n",
       "  'whislo': 2970367.6941847093,\n",
       "  'whishi': 11016705581.756739},\n",
       " {'mean': 1799504678.3529613,\n",
       "  'med': 176575392.96699834,\n",
       "  'q1': 19529202.6879844,\n",
       "  'q3': 1760173906.0016,\n",
       "  'whislo': 3108316.172358618,\n",
       "  'whishi': 11006584245.78804},\n",
       " {'mean': 1802351611.881844,\n",
       "  'med': 171248812.59442973,\n",
       "  'q1': 18499750.483724188,\n",
       "  'q3': 1763076621.183109,\n",
       "  'whislo': 2294336.99659983,\n",
       "  'whishi': 11041349312.00245},\n",
       " {'mean': 1802705457.5415905,\n",
       "  'med': 167177241.62848142,\n",
       "  'q1': 17965241.22176109,\n",
       "  'q3': 1776025357.8387918,\n",
       "  'whislo': 1852359.1081054052,\n",
       "  'whishi': 11049623533.652632},\n",
       " {'mean': 1797160393.590717,\n",
       "  'med': 164599446.3142,\n",
       "  'q1': 17814137.5762,\n",
       "  'q3': 1767608703.0147,\n",
       "  'whislo': 1791304.47535,\n",
       "  'whishi': 11060816660.3511}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_plot_token_stats = []\n",
    "for param_count in tqdm(split_to_param_count.values()):\n",
    "    model_examples = combined_dataframe[combined_dataframe[\"Param Count\"] == param_count]\n",
    "    box_plot_token_stats.append({\n",
    "        # \"label\": str(param_count),\n",
    "        \"mean\": model_examples[\"avg_frequency\"].mean(),\n",
    "        \"med\": model_examples[\"median_frequency\"].mean(),\n",
    "        \"q1\": model_examples[\"p25_frequency\"].mean(),\n",
    "        \"q3\": model_examples[\"p75_frequency\"].mean(),\n",
    "        \"whislo\": model_examples[\"min_frequency\"].mean(),\n",
    "        \"whishi\": model_examples[\"max_frequency\"].mean(),\n",
    "    })\n",
    "\n",
    "\n",
    "box_plot_token_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataframe = combined_dataframe.sort_values(\"Param Count\").dropna(subset=[\"sequence_perplexity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:15<00:21,  4.34s/it]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "['sequence_id', 'sequence_duplicates', 'max_frequency', 'avg_frequency',\n",
    "'min_frequency', 'median_frequency', 'p25_frequency', 'p75_frequency',\n",
    "'is_incrementing', 'repeating_offset', 'num_repeating',\n",
    "'smallest_repeating_chunk', 'memorization_score',\n",
    "'templating_frequency_0.9', 'templating_frequency_0.8',\n",
    "'prompt_perplexity', 'generation_perplexity', 'sequence_perplexity',\n",
    "'Model', 'Param Count', 'Deduped', 'Memorized', 'category']\n",
    "\"\"\"\n",
    "\n",
    "titles = {\n",
    "    # Categorical\n",
    "    \"category\": \"Count of Memories by Taxonomical Category\",\n",
    "    \"sequence_duplicates\": \"Mean Duplication Per Example\",\n",
    "    \"is_incrementing\": \"Percent of Sequences That Are Incrementing\",\n",
    "\n",
    "    # Length of repeating subsequences\n",
    "    \"num_repeating\": \"Mean Token Length For Repeating Subsequences\",\n",
    "\n",
    "    # Cosine Similarities\n",
    "    \"templating_frequency_0.9\": \"Mean Number of Examples 0.9 Cosime Similarity To Each Example\",\n",
    "    \"templating_frequency_0.8\": \"Mean Number of Examples 0.8 Cosime Similarity To Each Example\",\n",
    "\n",
    "    # Perplexity\n",
    "    # \"prompt_perplexity\": \"Mean Prompt Perplexity\",\n",
    "    # \"sequence_perplexity\": \"Mean Sequence Perplexity\",\n",
    "    # \"generation_perplexity\": \"Mean Generation Perplexity\",\n",
    "\n",
    "    # Token frequencies\n",
    "    # \"token_frequency\": \"Mean Token Frequency Statistics\",\n",
    "    \"median_frequency\": \"Mean Median Frequency for All Unique Tokens in Each Sequence\",\n",
    "    \"avg_frequency\": \"Mean Average Frequency for All Unique Tokens in Each Sequence\",\n",
    "    \"p25_frequency\": \"Mean 25th Percentile Frequency for All Unique Tokens in Each Sequence\",\n",
    "    \"min_frequency\": \"Mean Minimum Frequency for All Unique Tokens in Each Sequence\",\n",
    "}\n",
    "\n",
    "# create subplots where each metric is on its own row. The first column is fo rmemorized overall and the second is broken down by category.\n",
    "fig, axes = plt.subplots(len(titles), 2, figsize=(30, 15 * len(titles)))\n",
    "\n",
    "for metric in tqdm(titles):\n",
    "    for column in [0, 1]:\n",
    "        title_text = titles[metric]\n",
    "\n",
    "        if metric == \"token_frequency\":\n",
    "            sns.boxplot(\n",
    "                data=combined_dataframe,\n",
    "                y=\"avg_frequency\",\n",
    "                x=\"Model\",\n",
    "                ax=axes[list(titles.keys()).index(metric), column],\n",
    "                gap=0.5,\n",
    "                hue=\"category\" if column == 1 else \"Memorized\",\n",
    "            )\n",
    "\n",
    "        elif metric == \"category\":\n",
    "            if column == 0:\n",
    "                # histogram of the count of each category by model\n",
    "                sns.histplot(\n",
    "                    data=combined_dataframe[combined_dataframe[\"Memorized\"] == True],\n",
    "                    x=\"Model\",\n",
    "                    hue=\"category\",\n",
    "                    ax=axes[list(titles.keys()).index(metric), column],\n",
    "                    multiple=\"stack\",\n",
    "                    stat=\"count\",\n",
    "                    common_norm=False,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                fig.delaxes(axes[list(titles.keys()).index(metric), column])\n",
    "\n",
    "        else:\n",
    "            sns.lineplot(\n",
    "                data=combined_dataframe,\n",
    "                x=\"Param Count\",\n",
    "                y=metric,\n",
    "                ax=axes[list(titles.keys()).index(metric), column],\n",
    "                hue=\"category\" if column == 1 else \"Memorized\",\n",
    "            )\n",
    "\n",
    "        # log x axis if line plot\n",
    "        if metric not in [\"category\", \"token_frequency\"]:\n",
    "            axes[list(titles.keys()).index(metric), column].set_xscale(\"log\")\n",
    "\n",
    "        # set title\n",
    "        axes[list(titles.keys()).index(metric), column].set_title(title_text)\n",
    "\n",
    "        # make title bold\n",
    "        axes[list(titles.keys()).index(metric), column].title.set_weight(\"bold\")\n",
    "\n",
    "        # set x label based off the title\n",
    "        quant_metic = title_text.split()[0]\n",
    "        axes[list(titles.keys()).index(metric), column].set_ylabel(quant_metic)\n",
    "\n",
    "\n",
    "# add margins between rows\n",
    "plt.subplots_adjust(hspace=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memorization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
