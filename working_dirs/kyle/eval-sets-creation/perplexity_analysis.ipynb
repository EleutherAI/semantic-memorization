{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mchorse/.local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer, GPTNeoXForCausalLM, GPTNeoXConfig\n",
    "from torch.nn.functional import softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556518</th>\n",
       "      <td>98940518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1394, 778, 4044, 247, 3491, 273, 253, 4637, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797185</th>\n",
       "      <td>140365185</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[431, 1019, 8402, 94, 187, 50262, 61, 2099, 92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700522</th>\n",
       "      <td>21292522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[64, 11364, 1848, 8286, 64, 7310, 50261, 30, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149601</th>\n",
       "      <td>41333601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[387, 6831, 2363, 273, 4398, 938, 15, 17, 1584...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67235</th>\n",
       "      <td>80147235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4270, 327, 253, 2800, 7625, 11443, 8604, 60, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570694</th>\n",
       "      <td>45042694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[568, 37, 26649, 337, 15, 25, 15, 883, 5647, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258867</th>\n",
       "      <td>131674867</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[938, 3725, 47279, 8604, 60, 805, 431, 1019, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850610</th>\n",
       "      <td>49898610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[187, 1911, 634, 1211, 11743, 187, 187, 1911, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170213</th>\n",
       "      <td>142026213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[187, 249, 253, 9107, 1293, 12400, 13, 1690, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732253</th>\n",
       "      <td>124284253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[187, 50262, 61, 2099, 92, 8798, 94, 187, 5026...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             index  accuracy  \\\n",
       "556518    98940518       1.0   \n",
       "797185   140365185       1.0   \n",
       "700522    21292522       1.0   \n",
       "149601    41333601       1.0   \n",
       "67235     80147235       1.0   \n",
       "...            ...       ...   \n",
       "1570694   45042694       1.0   \n",
       "1258867  131674867       1.0   \n",
       "1850610   49898610       1.0   \n",
       "170213   142026213       1.0   \n",
       "732253   124284253       1.0   \n",
       "\n",
       "                                                    tokens  \n",
       "556518   [1394, 778, 4044, 247, 3491, 273, 253, 4637, 3...  \n",
       "797185   [431, 1019, 8402, 94, 187, 50262, 61, 2099, 92...  \n",
       "700522   [64, 11364, 1848, 8286, 64, 7310, 50261, 30, 4...  \n",
       "149601   [387, 6831, 2363, 273, 4398, 938, 15, 17, 1584...  \n",
       "67235    [4270, 327, 253, 2800, 7625, 11443, 8604, 60, ...  \n",
       "...                                                    ...  \n",
       "1570694  [568, 37, 26649, 337, 15, 25, 15, 883, 5647, 1...  \n",
       "1258867  [938, 3725, 47279, 8604, 60, 805, 431, 1019, 8...  \n",
       "1850610  [187, 1911, 634, 1211, 11743, 187, 187, 1911, ...  \n",
       "170213   [187, 249, 253, 9107, 1293, 12400, 13, 1690, 1...  \n",
       "732253   [187, 50262, 61, 2099, 92, 8798, 94, 187, 5026...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_hdf(\"memorized-data/19m.hdf\").sample(100)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "pythia_model = GPTNeoXForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")\n",
    "pythia_model.to(device)\n",
    "pythia_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=tensor(0.3538, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[[94.1922, 56.2604, 98.2960,  ..., 56.2614, 56.2595, 56.2630],\n",
       "         [96.4956, 54.3007, 97.5315,  ..., 54.3010, 54.2996, 54.3022],\n",
       "         [94.7728, 55.3570, 93.9256,  ..., 55.3577, 55.3552, 55.3580],\n",
       "         ...,\n",
       "         [47.5782, 19.7386, 42.1811,  ..., 19.7412, 19.7374, 19.7403],\n",
       "         [37.4160, 19.5540, 33.2688,  ..., 19.5539, 19.5515, 19.5540],\n",
       "         [53.2555, 24.4876, 54.1368,  ..., 24.4899, 24.4872, 24.4893]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>), past_key_values=((tensor([[[[-8.7410e-02,  1.4655e+00,  1.4457e+00,  ..., -5.1421e+00,\n",
       "            1.1504e+00,  7.0371e-01],\n",
       "          [-9.6436e-02, -5.2639e-01,  8.9948e-01,  ..., -4.5567e+00,\n",
       "            3.2489e-01,  1.7674e+00],\n",
       "          [ 9.1574e-02, -4.2861e-01,  8.3932e-02,  ..., -3.6315e+00,\n",
       "            1.0319e+00,  2.4560e+00],\n",
       "          ...,\n",
       "          [ 8.3537e-01, -5.1634e-02,  6.5463e-01,  ..., -3.8827e+00,\n",
       "           -8.8297e-02,  1.1449e+00],\n",
       "          [-9.9317e-01, -1.1410e+00,  1.9363e+00,  ..., -3.8662e+00,\n",
       "           -7.6932e-01,  8.5843e-01],\n",
       "          [ 2.8274e-01, -3.5337e-01,  1.1768e+00,  ..., -3.6288e+00,\n",
       "           -2.1462e-01,  1.9008e+00]],\n",
       "\n",
       "         [[-6.4664e-01,  1.0413e+00,  3.4274e-01,  ..., -4.9432e+00,\n",
       "           -3.7076e+00,  3.8773e+00],\n",
       "          [-1.8603e+00,  2.9702e+00,  3.2303e+00,  ..., -5.6917e+00,\n",
       "           -2.8691e+00,  3.0719e+00],\n",
       "          [ 1.0086e+00,  1.3191e+00,  3.2379e+00,  ..., -4.5502e+00,\n",
       "           -4.8388e+00,  5.2305e+00],\n",
       "          ...,\n",
       "          [ 3.1069e+00,  3.4244e+00,  3.0485e+00,  ..., -3.6985e+00,\n",
       "           -6.0187e+00,  5.6203e+00],\n",
       "          [ 5.5024e-01,  1.2201e+00,  1.1206e+00,  ..., -4.4681e+00,\n",
       "           -3.1868e+00,  3.4314e+00],\n",
       "          [ 4.3512e-01,  5.5121e-01,  1.0215e+00,  ..., -6.2036e+00,\n",
       "           -2.1392e+00,  2.6603e+00]],\n",
       "\n",
       "         [[-1.6555e-01, -1.1976e-01, -3.8785e-01,  ...,  7.6716e-01,\n",
       "            1.0442e+01, -5.2226e+00],\n",
       "          [-1.3415e+00, -7.3883e-01, -2.1664e-01,  ...,  1.6217e+00,\n",
       "            1.0265e+01, -5.0606e+00],\n",
       "          [-1.5772e+00, -6.4134e-01, -3.0309e-01,  ...,  1.4904e+00,\n",
       "            9.7659e+00, -3.9012e+00],\n",
       "          ...,\n",
       "          [ 2.3572e-02, -5.6252e-01, -6.4862e-02,  ..., -1.2229e+00,\n",
       "            9.5824e+00, -7.4578e+00],\n",
       "          [ 1.0312e+00, -4.4541e-01, -1.3799e+00,  ..., -1.8490e-01,\n",
       "            1.0337e+01, -4.1102e+00],\n",
       "          [-1.4435e+00,  1.9080e-01, -8.8848e-01,  ...,  1.6037e-01,\n",
       "            1.1747e+01, -3.9928e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.4197e+00, -2.1679e+00, -4.9101e+00,  ..., -3.1032e+00,\n",
       "            3.6781e-02, -1.0521e+01],\n",
       "          [ 6.5046e-01, -2.9437e+00, -4.5878e+00,  ..., -3.5672e+00,\n",
       "            5.9787e-01, -1.3835e+01],\n",
       "          [-3.3652e+00, -1.6366e+00, -2.7183e-01,  ..., -5.3480e+00,\n",
       "            3.4142e-01, -1.4351e+01],\n",
       "          ...,\n",
       "          [ 6.1599e-01, -1.7526e+00, -2.9723e+00,  ..., -4.9696e+00,\n",
       "            8.2635e-01, -1.0376e+01],\n",
       "          [ 8.0308e+00, -5.5675e+00, -5.7364e+00,  ..., -6.0389e+00,\n",
       "           -7.3215e-01, -1.1146e+01],\n",
       "          [ 2.8236e+00, -4.0425e+00, -3.9964e+00,  ..., -4.4482e+00,\n",
       "           -2.8348e+00, -1.2422e+01]],\n",
       "\n",
       "         [[-7.2006e-02,  1.3634e-01, -1.1836e+00,  ..., -6.2253e-01,\n",
       "           -5.6480e-01, -6.5333e+00],\n",
       "          [-1.2886e-02, -1.3347e-01,  4.7532e-01,  ..., -1.1298e+00,\n",
       "           -1.8027e-02, -8.9492e+00],\n",
       "          [-4.3652e-02, -6.5413e-01,  5.9019e-01,  ..., -1.5587e+00,\n",
       "            1.1048e-01, -7.4578e+00],\n",
       "          ...,\n",
       "          [-2.0785e-01,  1.1428e-01, -1.2262e-02,  ..., -1.2170e+00,\n",
       "           -5.4541e-01, -7.0688e+00],\n",
       "          [-3.8121e-01,  3.0907e-03, -2.4206e-01,  ..., -2.0533e+00,\n",
       "           -8.1435e-01, -8.6065e+00],\n",
       "          [-3.0324e-01, -4.2977e-01,  8.2369e-02,  ..., -1.5891e+00,\n",
       "            5.7525e-02, -9.1450e+00]],\n",
       "\n",
       "         [[-9.4532e-01, -9.5333e-01, -2.9062e+00,  ..., -6.8838e-01,\n",
       "           -9.1074e-01, -3.2234e+00],\n",
       "          [-8.2114e-01, -2.3515e-01, -1.5365e+00,  ..., -1.4092e+00,\n",
       "           -2.1428e-01, -3.1204e+00],\n",
       "          [-4.0166e-01, -8.3516e-01,  5.7833e-02,  ..., -1.4871e-02,\n",
       "           -1.8857e+00, -2.6764e+00],\n",
       "          ...,\n",
       "          [ 1.4452e+00, -6.4435e-01, -8.7892e-03,  ..., -1.9165e-01,\n",
       "           -1.1890e+00, -3.6209e+00],\n",
       "          [-1.3804e-01,  1.5688e+00, -1.4866e+00,  ...,  8.3829e-01,\n",
       "           -2.5834e+00, -2.9591e+00],\n",
       "          [-1.6753e+00,  1.2382e+00, -1.3788e+00,  ...,  4.6251e-01,\n",
       "           -2.5076e+00, -1.9782e+00]]]], device='cuda:0',\n",
       "       grad_fn=<CatBackward0>), tensor([[[[ 0.7612, -0.0167,  0.2194,  ..., -1.2179,  0.3766, -0.1961],\n",
       "          [-1.2309, -0.3151, -0.2707,  ...,  0.8522,  0.1520,  0.4070],\n",
       "          [ 0.1938,  0.0952, -0.0935,  ...,  0.1460, -0.0624, -0.2442],\n",
       "          ...,\n",
       "          [-0.6238,  0.1814,  0.0445,  ...,  0.4058, -0.1647,  0.0380],\n",
       "          [-0.5534,  0.1938,  0.1246,  ..., -0.0036,  0.4340, -0.1539],\n",
       "          [ 0.9191,  0.6173, -0.3988,  ...,  0.5504, -0.0788,  0.0395]],\n",
       "\n",
       "         [[ 0.1352, -0.0127, -0.3027,  ..., -0.1648, -0.1482,  0.2758],\n",
       "          [-0.0173, -0.1768,  0.5026,  ...,  0.0111,  0.3187,  0.2178],\n",
       "          [ 0.3193, -0.1033, -0.0381,  ...,  0.4215,  0.0309,  0.2000],\n",
       "          ...,\n",
       "          [-0.1526,  0.6301, -0.2068,  ..., -0.6725, -0.2476,  0.2671],\n",
       "          [-0.3546,  0.5544, -0.2895,  ...,  0.2276,  0.2084, -0.2389],\n",
       "          [-0.5315,  0.8005,  0.3160,  ..., -0.6646,  0.4877,  0.1021]],\n",
       "\n",
       "         [[-0.0486, -0.2837, -1.1902,  ...,  0.7283, -0.7044, -0.3952],\n",
       "          [-0.0859,  0.2208, -0.2345,  ...,  0.7085,  0.1609, -0.1132],\n",
       "          [-0.0889, -0.4502, -0.6922,  ...,  0.4873, -0.0124, -0.1953],\n",
       "          ...,\n",
       "          [ 0.0659,  0.2070,  0.2539,  ..., -0.0074, -0.2960, -0.0761],\n",
       "          [ 0.0915, -0.0357, -0.4489,  ...,  0.5790,  0.1054, -0.3460],\n",
       "          [-0.0627,  0.2449, -0.5055,  ...,  0.1466, -0.0246,  0.2594]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.7363,  0.3004,  0.3856,  ..., -0.3022,  0.6634,  0.6985],\n",
       "          [-0.1769, -0.0528,  0.8086,  ...,  0.1845, -0.3585, -0.4308],\n",
       "          [ 0.6778,  0.1418, -0.2719,  ...,  0.2567, -0.7549, -0.4394],\n",
       "          ...,\n",
       "          [ 0.6208,  0.6879,  1.0851,  ..., -0.0448, -0.0359,  0.3786],\n",
       "          [-1.7816,  0.3836,  0.1651,  ...,  0.5050, -0.4461,  0.0631],\n",
       "          [-0.6152, -0.5367,  1.2149,  ...,  0.1973,  0.4212,  0.9633]],\n",
       "\n",
       "         [[-0.4404,  1.0126, -0.3825,  ...,  1.1610, -0.3780,  0.1144],\n",
       "          [-0.2237,  0.2152, -0.1199,  ..., -0.6674, -0.1265, -0.8083],\n",
       "          [ 0.5050,  0.5449,  0.0282,  ..., -1.3333, -0.2154, -1.4943],\n",
       "          ...,\n",
       "          [-0.1914, -0.1905, -0.1299,  ..., -0.2743, -0.1214, -0.4327],\n",
       "          [-0.0881, -0.1621,  0.3675,  ...,  0.4834, -0.7984, -0.0746],\n",
       "          [-0.5468, -0.2054,  0.1371,  ...,  1.0939, -0.2589,  0.6779]],\n",
       "\n",
       "         [[ 0.0775,  0.3942,  0.1714,  ..., -0.5668,  1.7499, -0.1480],\n",
       "          [-0.0352,  0.0459,  0.1048,  ..., -0.0541,  0.7339,  0.1249],\n",
       "          [ 0.3533,  0.2842, -0.4828,  ...,  0.3868,  0.1812,  0.3089],\n",
       "          ...,\n",
       "          [-0.2649,  0.7801,  0.4460,  ...,  0.4972,  0.1482, -0.2472],\n",
       "          [ 0.3920, -0.2999,  0.5864,  ...,  0.5297,  0.7202, -0.2230],\n",
       "          [-0.6812, -0.7096,  1.3822,  ...,  1.0156, -0.3612, -0.5020]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>)), (tensor([[[[-5.1423e-01,  5.7159e-01, -7.4367e-02,  ...,  7.2873e+00,\n",
       "            1.1561e+00, -1.2538e+00],\n",
       "          [-8.9602e-01,  2.7774e+00,  8.6581e-01,  ...,  6.2184e+00,\n",
       "            1.0097e+00, -2.3147e+00],\n",
       "          [ 7.6009e-01,  1.4725e+00,  1.5520e+00,  ...,  5.8624e+00,\n",
       "            1.0440e+00, -1.4328e+00],\n",
       "          ...,\n",
       "          [-2.2033e-01,  1.2895e+00,  1.3699e+00,  ...,  6.0184e+00,\n",
       "            7.5238e-01, -3.2357e+00],\n",
       "          [ 8.2133e-01,  1.6366e+00,  1.3756e+00,  ...,  6.7065e+00,\n",
       "            2.1801e+00, -1.6483e+00],\n",
       "          [-1.9222e-01,  9.9508e-01, -2.9399e-01,  ...,  6.7500e+00,\n",
       "           -4.1209e-01, -4.5471e+00]],\n",
       "\n",
       "         [[-6.7007e-01, -1.3520e-01, -5.2084e-01,  ...,  3.7610e+00,\n",
       "            9.4887e+00,  4.6786e+00],\n",
       "          [-1.9387e+00,  2.8893e-01, -1.2606e+00,  ...,  3.1339e+00,\n",
       "            8.0381e+00,  5.6256e+00],\n",
       "          [ 2.8281e-01,  2.5753e-02, -2.3864e+00,  ...,  4.0966e+00,\n",
       "            7.4414e+00,  5.3712e+00],\n",
       "          ...,\n",
       "          [-3.8272e-01,  3.6851e-01, -2.3974e-01,  ...,  3.8482e+00,\n",
       "            6.5850e+00,  4.2394e+00],\n",
       "          [-1.0472e+00,  9.0836e-01, -1.7888e+00,  ...,  4.7933e+00,\n",
       "            7.7708e+00,  4.5023e+00],\n",
       "          [ 1.5097e+00, -2.0152e-02, -2.7585e+00,  ...,  1.6852e+00,\n",
       "            4.5248e+00,  5.6360e+00]],\n",
       "\n",
       "         [[ 5.0919e-01, -2.6892e+00, -3.3516e+00,  ..., -1.0257e+00,\n",
       "           -7.6923e-01,  3.4457e+00],\n",
       "          [ 3.7116e+00, -1.9119e+00, -3.4603e+00,  ..., -1.2685e+00,\n",
       "           -9.4645e-01,  2.6793e+00],\n",
       "          [ 3.4049e+00, -1.9873e-01, -3.5646e+00,  ..., -3.8203e-01,\n",
       "           -2.2173e+00,  4.0246e+00],\n",
       "          ...,\n",
       "          [-7.4827e+00, -2.1305e+00, -4.8626e+00,  ..., -1.6200e+00,\n",
       "           -3.5973e+00,  3.1670e+00],\n",
       "          [-3.4519e+00, -2.8018e-01, -5.6335e+00,  ..., -6.7212e-01,\n",
       "           -2.1911e+00,  3.5694e+00],\n",
       "          [ 1.4525e+00,  1.5150e+00, -2.9312e+00,  ..., -3.2723e+00,\n",
       "           -4.1138e-03,  3.4550e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.6093e+00, -1.8964e+00, -1.9240e+00,  ..., -7.6173e+00,\n",
       "            1.4362e+00,  7.9339e+00],\n",
       "          [ 1.1563e+00, -8.5385e-01, -1.7197e+00,  ..., -6.4921e+00,\n",
       "            1.1051e+00,  7.9133e+00],\n",
       "          [ 5.0750e-01,  8.2852e-01, -8.4367e-01,  ..., -6.5952e+00,\n",
       "            1.7832e+00,  8.6793e+00],\n",
       "          ...,\n",
       "          [-1.5811e+00,  4.5636e-01, -1.5154e+00,  ..., -1.0253e+01,\n",
       "            2.1353e+00,  8.6435e+00],\n",
       "          [-2.5434e+00,  1.2261e+00, -1.9570e+00,  ..., -5.8944e+00,\n",
       "            1.5215e+00,  7.6625e+00],\n",
       "          [-2.0174e-01, -3.3524e-01, -9.9222e-01,  ..., -8.6413e+00,\n",
       "            3.8297e-01,  6.3240e+00]],\n",
       "\n",
       "         [[ 2.3831e+00, -3.7049e+00,  6.1935e-01,  ...,  4.9644e+00,\n",
       "            1.2220e+01, -9.4957e+00],\n",
       "          [ 1.1642e+00, -1.3938e+00,  6.5184e-01,  ...,  4.7087e+00,\n",
       "            1.0610e+01, -1.0259e+01],\n",
       "          [-6.8837e-03, -2.3514e+00,  2.1453e-01,  ...,  5.0284e+00,\n",
       "            1.1854e+01, -8.2082e+00],\n",
       "          ...,\n",
       "          [-1.4397e+00, -1.5916e+00,  3.9714e+00,  ...,  5.8703e+00,\n",
       "            1.1732e+01, -1.0225e+01],\n",
       "          [ 7.8517e-02, -2.0540e+00,  3.4761e+00,  ...,  5.9099e+00,\n",
       "            1.1591e+01, -1.0210e+01],\n",
       "          [-4.1693e-01, -8.3226e-01,  7.7743e-02,  ...,  3.9869e+00,\n",
       "            1.1683e+01, -1.5439e+01]],\n",
       "\n",
       "         [[ 3.1587e-01,  7.0212e-01, -1.1203e+00,  ...,  9.8157e+00,\n",
       "            3.1464e+00,  5.7342e+00],\n",
       "          [ 1.3952e-03,  2.2290e-01, -1.6115e+00,  ...,  9.7358e+00,\n",
       "            2.5701e+00,  6.0893e+00],\n",
       "          [-2.6569e-02, -7.6596e-02, -6.9881e-01,  ...,  1.0097e+01,\n",
       "            4.7374e-01,  7.0523e+00],\n",
       "          ...,\n",
       "          [ 6.3110e-01,  6.1323e-01, -1.0541e+00,  ...,  7.4828e+00,\n",
       "            3.0961e-01,  6.3134e+00],\n",
       "          [ 1.9378e+00,  8.6930e-01, -2.5293e+00,  ...,  8.7941e+00,\n",
       "            1.5790e+00,  6.4511e+00],\n",
       "          [ 3.6610e-01,  2.9592e-01, -2.5567e+00,  ...,  8.3196e+00,\n",
       "            1.6902e+00,  5.3218e+00]]]], device='cuda:0',\n",
       "       grad_fn=<CatBackward0>), tensor([[[[-0.9885,  0.3339,  0.7358,  ...,  0.2899, -0.4778,  0.2673],\n",
       "          [-0.8287, -1.0387,  0.4063,  ..., -0.0192,  0.4184, -0.0486],\n",
       "          [-0.1900, -0.3118, -0.7763,  ...,  0.4462,  0.3665,  0.5674],\n",
       "          ...,\n",
       "          [ 0.7961, -0.0465,  0.5731,  ...,  0.7092,  0.0385,  0.2690],\n",
       "          [ 0.7153, -0.4330, -0.2501,  ...,  0.2935,  0.0266,  0.9108],\n",
       "          [ 0.2674, -0.0122,  0.3490,  ..., -0.6838,  0.0061, -0.3003]],\n",
       "\n",
       "         [[-0.1415,  0.0707,  0.3385,  ..., -0.2918, -0.2056,  0.1578],\n",
       "          [-0.1908, -0.5068, -0.1489,  ...,  0.5295,  0.1496,  0.0310],\n",
       "          [ 0.2214,  0.1395,  0.1240,  ..., -0.3479, -0.7182, -0.3723],\n",
       "          ...,\n",
       "          [-0.6012, -0.6134,  0.2463,  ..., -0.3438,  0.4853, -0.0686],\n",
       "          [ 1.0016, -0.4912,  0.3408,  ..., -0.7335, -0.3154,  0.3177],\n",
       "          [-0.2036,  0.8577,  0.0654,  ..., -0.0122, -0.4047,  1.0209]],\n",
       "\n",
       "         [[ 0.0173, -0.2028, -0.3103,  ...,  0.0129,  0.6706, -0.3077],\n",
       "          [ 0.5305,  0.1374,  1.3292,  ..., -0.5588, -0.6262,  1.0145],\n",
       "          [ 0.2085, -0.2033,  0.7991,  ..., -0.3851, -0.0673,  0.9143],\n",
       "          ...,\n",
       "          [-0.0205, -0.6025, -0.2375,  ..., -0.1255, -0.3088,  0.9875],\n",
       "          [-0.3993, -0.7814,  0.1423,  ..., -0.2908, -0.1478, -0.6880],\n",
       "          [ 0.5400,  0.2982,  1.3982,  ...,  0.0243, -1.0445,  0.0478]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.2063,  0.6464, -0.6931,  ...,  0.6187, -0.1235,  0.0469],\n",
       "          [-0.0142, -0.0136, -0.5902,  ...,  0.0930, -0.1205,  0.2732],\n",
       "          [-0.0915, -0.1434, -0.1812,  ...,  0.6206, -0.7191,  0.1505],\n",
       "          ...,\n",
       "          [-0.7467,  0.3219, -0.0910,  ...,  0.1316, -0.2767, -0.5579],\n",
       "          [ 0.5343,  0.4733, -0.1158,  ...,  0.0818, -0.1436,  0.2620],\n",
       "          [-0.4474,  0.1915, -0.0717,  ...,  1.0810, -0.1029, -0.2923]],\n",
       "\n",
       "         [[-0.6361,  1.0673, -0.0231,  ..., -0.9359, -0.3037,  0.5444],\n",
       "          [ 0.4314,  0.5158, -0.7252,  ..., -0.0235,  0.3145, -0.5513],\n",
       "          [-0.1745, -0.1275, -0.6806,  ..., -0.3905, -0.3176, -0.5983],\n",
       "          ...,\n",
       "          [ 0.6063,  0.2967, -0.0193,  ...,  0.1480, -0.0238,  0.2356],\n",
       "          [ 0.4630,  0.9595, -0.4489,  ..., -0.3181, -0.9238,  0.5243],\n",
       "          [ 0.1743, -0.7126, -0.2149,  ..., -0.4552,  0.2572,  0.0537]],\n",
       "\n",
       "         [[-0.5935,  0.0024, -0.0073,  ..., -0.6720, -0.4807, -0.0987],\n",
       "          [-0.6731,  0.2225,  0.0485,  ...,  0.3197,  0.0820, -0.0547],\n",
       "          [-0.6191, -0.3552,  0.5628,  ...,  0.0212, -0.0135,  0.4453],\n",
       "          ...,\n",
       "          [-0.4877, -0.2099, -0.1585,  ...,  0.1589, -0.0154, -0.3079],\n",
       "          [ 0.1364,  0.8627,  0.7422,  ...,  0.3016, -0.4953, -0.0282],\n",
       "          [ 0.1508,  1.2135,  0.8672,  ...,  0.2356, -0.0104, -0.2142]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>)), (tensor([[[[-1.4570e-01, -3.6638e-01,  2.1307e+00,  ..., -4.6211e+00,\n",
       "           -8.1994e+00, -6.7025e+00],\n",
       "          [ 1.6089e-01, -1.2777e-01,  2.2433e+00,  ..., -4.7589e+00,\n",
       "           -7.8959e+00, -6.6042e+00],\n",
       "          [ 4.6698e-01, -1.0081e+00,  2.2077e+00,  ..., -4.4047e+00,\n",
       "           -7.2487e+00, -5.4080e+00],\n",
       "          ...,\n",
       "          [-6.8720e-01, -2.0662e-01,  1.0480e+00,  ..., -5.3633e+00,\n",
       "           -6.5945e+00, -5.5431e+00],\n",
       "          [-7.5055e-01, -1.5803e+00,  1.0401e+00,  ..., -5.3771e+00,\n",
       "           -7.8638e+00, -6.6001e+00],\n",
       "          [ 1.4411e-01, -4.5946e-01,  3.1069e+00,  ..., -5.0579e+00,\n",
       "           -6.8480e+00, -7.3302e+00]],\n",
       "\n",
       "         [[ 6.2281e+00,  5.2204e+00, -5.0888e+00,  ...,  4.1750e+00,\n",
       "            2.9426e+00,  1.1732e+00],\n",
       "          [ 6.5230e+00,  4.9866e+00, -5.1494e+00,  ...,  3.6931e+00,\n",
       "            3.3297e+00,  1.2316e+00],\n",
       "          [ 1.4038e+00,  4.1873e+00, -5.1669e+00,  ...,  3.6395e+00,\n",
       "            3.2476e+00,  1.7962e+00],\n",
       "          ...,\n",
       "          [-5.3582e+00,  4.1805e+00, -4.5559e+00,  ...,  4.4587e+00,\n",
       "            2.0927e+00,  1.7895e+00],\n",
       "          [ 9.0237e-01,  2.3582e+00, -4.5223e+00,  ...,  4.2915e+00,\n",
       "            2.6305e+00,  2.4716e+00],\n",
       "          [ 4.8183e+00,  1.7463e-01, -4.5961e+00,  ...,  3.6846e+00,\n",
       "            2.8233e+00,  3.0703e+00]],\n",
       "\n",
       "         [[-6.7279e-01,  3.7046e-01, -1.4471e+00,  ...,  1.3419e+01,\n",
       "            1.9445e+00, -2.5884e+00],\n",
       "          [-6.9276e-01, -4.6647e-01, -3.1974e+00,  ...,  1.2619e+01,\n",
       "            2.1375e+00, -2.7434e+00],\n",
       "          [ 1.7407e-01, -1.3035e-01, -3.1992e+00,  ...,  1.2081e+01,\n",
       "            1.5470e+00, -2.2157e+00],\n",
       "          ...,\n",
       "          [-1.2476e-03,  5.5552e-01, -4.1536e+00,  ...,  1.3387e+01,\n",
       "            6.1459e-01, -1.6603e+00],\n",
       "          [-7.1204e-01,  2.5855e-01, -3.8995e+00,  ...,  1.3189e+01,\n",
       "            9.5894e-01, -2.5495e+00],\n",
       "          [-4.4391e-01,  1.1967e-01, -3.7699e+00,  ...,  1.2320e+01,\n",
       "            7.8822e-01, -2.9498e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-9.1916e-01,  2.2647e-01,  1.4561e+00,  ...,  5.9121e+00,\n",
       "           -2.0938e+00,  3.6128e+00],\n",
       "          [ 5.8502e-01,  1.1596e-01, -7.7307e-02,  ...,  5.0779e+00,\n",
       "           -1.7618e+00,  4.0280e+00],\n",
       "          [ 1.0380e+00,  2.7525e-02,  5.3563e-01,  ...,  4.3046e+00,\n",
       "           -3.0912e+00,  3.2866e+00],\n",
       "          ...,\n",
       "          [-4.6535e-01, -5.7653e-01,  6.5256e-01,  ...,  4.9007e+00,\n",
       "           -6.9650e-01,  3.8909e+00],\n",
       "          [-1.0369e-01, -3.5560e-01,  8.9654e-01,  ...,  5.9275e+00,\n",
       "           -1.6512e+00,  3.4523e+00],\n",
       "          [ 2.5596e-01, -2.5066e-01,  1.0234e+00,  ...,  4.4530e+00,\n",
       "           -3.6547e+00,  4.8973e+00]],\n",
       "\n",
       "         [[-1.2518e-01, -5.6577e-01, -1.5634e+00,  ...,  1.1836e+01,\n",
       "            9.8034e-01,  1.1628e+01],\n",
       "          [ 1.5902e-01, -8.4322e-01, -1.4610e+00,  ...,  1.3084e+01,\n",
       "            6.3507e-01,  1.3614e+01],\n",
       "          [ 1.3169e-01, -6.5610e-01, -1.8035e+00,  ...,  1.3087e+01,\n",
       "            1.0785e+00,  1.3465e+01],\n",
       "          ...,\n",
       "          [-3.9859e-01,  6.8986e-01, -2.2902e+00,  ...,  1.1615e+01,\n",
       "            1.6927e-01,  1.2797e+01],\n",
       "          [ 1.4091e-01,  5.0874e-01, -2.9052e+00,  ...,  1.2693e+01,\n",
       "            9.1957e-01,  1.3475e+01],\n",
       "          [ 7.9625e-01, -4.7751e-03, -1.8893e+00,  ...,  1.3651e+01,\n",
       "            1.0207e+00,  1.4445e+01]],\n",
       "\n",
       "         [[-2.0075e+00, -3.1967e-01,  4.6664e-01,  ...,  1.5956e+01,\n",
       "            2.5231e+01,  5.9292e+00],\n",
       "          [-9.3031e-01, -1.7429e+00,  2.4596e+00,  ...,  1.6300e+01,\n",
       "            2.4655e+01,  6.2577e+00],\n",
       "          [ 2.3770e+00, -1.8638e+00,  3.8805e+00,  ...,  1.5735e+01,\n",
       "            2.5126e+01,  6.0674e+00],\n",
       "          ...,\n",
       "          [-1.8089e+00, -4.3297e+00,  2.4387e+00,  ...,  1.4738e+01,\n",
       "            2.6670e+01,  4.4894e+00],\n",
       "          [-4.1389e+00, -4.3539e+00,  3.4748e+00,  ...,  1.4440e+01,\n",
       "            2.5619e+01,  4.7994e+00],\n",
       "          [-1.1357e+00, -1.9039e+00,  3.7774e+00,  ...,  1.3762e+01,\n",
       "            2.6044e+01,  6.6366e+00]]]], device='cuda:0',\n",
       "       grad_fn=<CatBackward0>), tensor([[[[ 1.2321, -0.2735,  0.1715,  ...,  0.0708, -0.4034,  0.3952],\n",
       "          [-0.1144, -0.1974, -0.1196,  ..., -0.1476, -0.3852, -0.4883],\n",
       "          [-0.9204, -0.5069, -0.5202,  ..., -0.0488, -0.0874, -0.7563],\n",
       "          ...,\n",
       "          [ 0.1290,  0.1001,  0.1473,  ..., -0.3248,  1.0028, -0.7621],\n",
       "          [ 1.1420, -0.6077,  0.2947,  ...,  0.2562, -0.6394, -0.7541],\n",
       "          [-0.2102,  0.2372,  0.5548,  ..., -0.1517, -0.5921,  0.0134]],\n",
       "\n",
       "         [[-0.2102,  0.4855, -0.6524,  ...,  0.0048, -0.2708, -0.0541],\n",
       "          [-0.5718,  0.0567, -0.4447,  ..., -0.4010, -0.8072,  0.6143],\n",
       "          [-0.6517, -0.1405, -0.2497,  ..., -0.5455, -0.1491, -0.1980],\n",
       "          ...,\n",
       "          [ 0.3281, -0.8090,  0.9461,  ..., -0.6758, -0.1560, -0.0565],\n",
       "          [ 0.5359, -0.0449, -0.0194,  ...,  0.4497, -0.9783, -0.0066],\n",
       "          [-0.3260,  0.3176,  0.2907,  ...,  0.1154, -0.2675, -0.9406]],\n",
       "\n",
       "         [[ 0.0398, -0.3838,  0.0182,  ...,  0.0377, -1.1935,  0.3317],\n",
       "          [ 0.3640, -0.4414,  1.1585,  ..., -1.7304,  1.7318, -0.0604],\n",
       "          [ 0.1014, -0.8149, -0.1303,  ..., -1.3703,  0.9934, -0.2222],\n",
       "          ...,\n",
       "          [ 0.0644, -0.2356, -0.5738,  ...,  0.5972,  0.1725,  1.3312],\n",
       "          [ 0.2182, -2.0000,  0.6624,  ...,  1.2939, -0.7878, -0.4038],\n",
       "          [ 0.7332, -0.5732,  0.5673,  ..., -0.2115, -1.3590, -0.5302]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.2052,  0.1900,  0.1544,  ..., -0.0587, -0.3463,  0.4290],\n",
       "          [-0.0230,  0.0837, -0.5145,  ..., -0.6038, -0.5753,  0.3040],\n",
       "          [ 0.2624, -0.2330,  0.0281,  ...,  0.1910,  0.1693,  0.7540],\n",
       "          ...,\n",
       "          [-0.4496, -0.3797, -0.6084,  ...,  0.5425,  0.3408,  0.5732],\n",
       "          [ 0.1761,  0.9650, -0.7936,  ...,  0.8161,  0.6955,  0.4811],\n",
       "          [ 1.0880, -0.7926, -0.4760,  ..., -0.6855,  0.8227, -0.4854]],\n",
       "\n",
       "         [[-0.1898,  0.6159, -0.0022,  ..., -0.0570, -0.9569,  0.0024],\n",
       "          [-0.1337, -1.6232, -0.7686,  ..., -0.4056, -0.4024,  0.1834],\n",
       "          [ 0.6469, -0.8662, -0.3919,  ..., -0.4988, -0.4396,  0.1390],\n",
       "          ...,\n",
       "          [ 0.0060,  0.9920,  0.3751,  ..., -0.4878,  0.3834,  0.3997],\n",
       "          [-0.0035,  0.2642, -0.4322,  ..., -0.3628,  0.5621, -0.1384],\n",
       "          [ 0.1269, -0.3949,  0.0133,  ..., -0.2876,  0.1328,  0.3980]],\n",
       "\n",
       "         [[-0.3179,  0.2238,  0.3748,  ...,  0.1308, -0.2005, -0.1081],\n",
       "          [-0.2641,  0.4770,  0.5654,  ...,  0.2652, -0.2590, -0.1406],\n",
       "          [ 0.1107,  0.0120, -0.0520,  ...,  0.3007, -0.2317, -0.3066],\n",
       "          ...,\n",
       "          [-1.0086,  0.1926,  0.2702,  ..., -0.1539,  0.1975, -0.2970],\n",
       "          [-0.4006, -0.7000,  0.0133,  ...,  0.4649, -0.0971, -0.5058],\n",
       "          [ 0.1601,  0.5442,  0.2103,  ..., -0.1781,  0.4005, -0.3795]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>)), (tensor([[[[-1.2888e-02, -1.6222e-02, -9.2146e-03,  ..., -5.9639e+01,\n",
       "           -6.2759e+01, -5.5334e+01],\n",
       "          [ 1.1056e+00,  1.4000e+00,  1.6976e+00,  ..., -6.0653e+01,\n",
       "           -6.2182e+01, -5.6763e+01],\n",
       "          [ 1.2902e+00,  1.9339e+00,  1.3887e+00,  ..., -5.8830e+01,\n",
       "           -6.1031e+01, -5.4591e+01],\n",
       "          ...,\n",
       "          [-5.2613e-01,  2.9580e-01,  3.0072e-02,  ..., -5.8656e+01,\n",
       "           -6.2649e+01, -5.5060e+01],\n",
       "          [-1.3541e+00,  6.0676e-01,  4.7102e-01,  ..., -5.9686e+01,\n",
       "           -6.3434e+01, -5.5126e+01],\n",
       "          [-1.7988e+00,  2.4084e+00,  2.3948e+00,  ..., -6.1653e+01,\n",
       "           -6.2802e+01, -5.4909e+01]],\n",
       "\n",
       "         [[-7.6596e-02,  2.0951e-02,  2.0751e-01,  ...,  2.7245e+01,\n",
       "           -4.4477e+01, -5.7747e+01],\n",
       "          [-1.3591e+00,  3.6546e-01,  7.9367e-01,  ...,  1.9492e+01,\n",
       "           -4.8185e+01, -5.7771e+01],\n",
       "          [ 3.9381e-01, -1.0851e-01,  6.5082e-02,  ...,  1.4882e+01,\n",
       "           -4.7304e+01, -5.8141e+01],\n",
       "          ...,\n",
       "          [ 1.1158e+00, -5.1143e-02, -2.5850e-01,  ...,  1.6759e+01,\n",
       "           -4.9523e+01, -5.6626e+01],\n",
       "          [-1.3568e+00,  1.7874e-01,  8.3070e-01,  ...,  1.7001e+01,\n",
       "           -4.9454e+01, -5.8262e+01],\n",
       "          [-1.3376e+00,  1.7125e-01, -1.2688e-02,  ...,  2.1711e+01,\n",
       "           -5.1141e+01, -5.7380e+01]],\n",
       "\n",
       "         [[-1.2814e-02, -4.3470e-01,  6.7648e-01,  ..., -9.4221e+00,\n",
       "            4.9747e+00,  5.6302e-01],\n",
       "          [-9.6644e-02,  3.2010e-01,  6.0150e-01,  ..., -1.0153e+01,\n",
       "            4.4069e+00,  5.1730e-01],\n",
       "          [ 2.1203e-01, -2.3361e-01,  5.3016e-01,  ..., -9.9411e+00,\n",
       "            3.7800e+00, -7.0046e-03],\n",
       "          ...,\n",
       "          [ 1.5885e+00, -7.7448e-01,  1.4957e+00,  ..., -9.7087e+00,\n",
       "            3.9817e+00, -4.4102e-01],\n",
       "          [ 6.0582e-01, -1.7938e-01,  8.9014e-01,  ..., -1.0067e+01,\n",
       "            3.6095e+00, -5.1703e-01],\n",
       "          [-1.0285e+00,  9.1333e-01,  1.6743e+00,  ..., -9.5231e+00,\n",
       "            4.1171e+00, -1.6505e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.5179e-02, -1.5904e-01,  1.8797e-01,  ..., -4.7873e+01,\n",
       "           -5.4427e+01, -4.6547e+01],\n",
       "          [ 3.5494e-02,  2.3677e-01, -1.2405e+00,  ..., -4.7136e+01,\n",
       "           -5.4097e+01, -4.7571e+01],\n",
       "          [-8.1409e-01,  6.1565e-01, -1.4371e+00,  ..., -4.8225e+01,\n",
       "           -5.4653e+01, -4.7611e+01],\n",
       "          ...,\n",
       "          [ 2.9801e-01,  4.1016e-01, -6.9663e-01,  ..., -4.6582e+01,\n",
       "           -5.6465e+01, -4.6103e+01],\n",
       "          [-7.2813e-01,  1.9834e+00, -1.6619e+00,  ..., -4.7675e+01,\n",
       "           -5.5183e+01, -4.7889e+01],\n",
       "          [-3.5609e-01,  2.5121e+00, -1.0968e+00,  ..., -4.8302e+01,\n",
       "           -5.5335e+01, -4.7505e+01]],\n",
       "\n",
       "         [[ 1.1379e-01,  9.7433e-02,  1.7738e-01,  ...,  6.6345e+01,\n",
       "           -6.4599e+01, -6.4709e+01],\n",
       "          [-3.3109e-01, -1.1624e+00, -4.1016e-01,  ...,  6.7906e+01,\n",
       "           -6.4971e+01, -6.5605e+01],\n",
       "          [-3.7009e-01, -2.2162e+00, -1.4083e+00,  ...,  6.6394e+01,\n",
       "           -6.4833e+01, -6.5173e+01],\n",
       "          ...,\n",
       "          [ 1.3470e+00, -1.8798e+00, -1.8260e+00,  ...,  6.3737e+01,\n",
       "           -6.3185e+01, -6.5731e+01],\n",
       "          [ 8.7993e-01, -2.3558e-03, -1.6298e+00,  ...,  6.6350e+01,\n",
       "           -6.3868e+01, -6.5163e+01],\n",
       "          [ 9.3263e-02,  7.2162e-01, -7.2067e-01,  ...,  6.5541e+01,\n",
       "           -6.4122e+01, -6.4010e+01]],\n",
       "\n",
       "         [[ 9.0079e-02, -1.5360e-01, -8.2123e-02,  ..., -1.4670e+01,\n",
       "            1.6836e+00,  9.8724e+00],\n",
       "          [-8.8108e-01, -7.9265e-01, -2.3135e-01,  ..., -1.3532e+01,\n",
       "            6.6757e-01,  9.2051e+00],\n",
       "          [-1.4772e+00, -1.5196e+00, -3.6470e-01,  ..., -1.4368e+01,\n",
       "            1.2445e+00,  1.0567e+01],\n",
       "          ...,\n",
       "          [ 9.1258e-01, -1.2112e+00, -2.4244e+00,  ..., -1.5566e+01,\n",
       "           -3.6894e-02,  9.6548e+00],\n",
       "          [ 6.6857e-01, -6.6903e-01, -1.8258e+00,  ..., -1.6871e+01,\n",
       "            4.4712e-01,  1.0418e+01],\n",
       "          [-6.7235e-01,  1.8692e-01, -1.0785e+00,  ..., -1.6070e+01,\n",
       "            9.1221e-01,  9.7806e+00]]]], device='cuda:0',\n",
       "       grad_fn=<CatBackward0>), tensor([[[[-4.7097e-02, -3.6878e-02, -1.8906e-03,  ...,  3.8385e-02,\n",
       "           -1.6858e-02,  3.2887e-02],\n",
       "          [ 4.5684e-03,  5.4236e-01, -3.3103e-02,  ...,  8.6443e-01,\n",
       "            3.1812e-02,  4.5287e-01],\n",
       "          [-5.5308e-01, -2.5416e-01, -5.1032e-01,  ..., -1.8380e-01,\n",
       "           -1.0653e-01,  2.8958e-01],\n",
       "          ...,\n",
       "          [ 2.9679e-01, -4.6589e-01, -5.8174e-01,  ...,  3.2748e-02,\n",
       "            7.6065e-02, -4.0689e-01],\n",
       "          [ 7.4838e-01, -1.2873e+00, -1.6729e-01,  ...,  2.2545e-01,\n",
       "            1.9665e-01, -3.0010e-02],\n",
       "          [ 1.5846e-01, -9.3121e-01, -8.3740e-01,  ..., -7.6082e-01,\n",
       "           -1.8278e-01, -4.5239e-01]],\n",
       "\n",
       "         [[ 2.4864e-02,  5.2044e-02, -4.3292e-02,  ...,  1.9771e-02,\n",
       "           -3.9040e-02,  6.9191e-02],\n",
       "          [-1.6043e+00, -2.4683e-02, -6.5547e-01,  ...,  8.7671e-01,\n",
       "            1.1789e+00, -4.2547e-01],\n",
       "          [-8.7252e-01,  3.4297e-01, -5.8053e-01,  ...,  3.8617e-01,\n",
       "            3.0690e-01, -1.0754e+00],\n",
       "          ...,\n",
       "          [ 1.3735e-01, -4.2587e-01,  1.0135e-01,  ...,  7.2780e-01,\n",
       "            9.2770e-01, -5.9673e-02],\n",
       "          [-1.1839e-01, -4.0680e-01,  6.2586e-01,  ...,  9.5032e-01,\n",
       "           -3.6525e-01,  9.0348e-01],\n",
       "          [-1.3890e-01,  6.4887e-01, -2.0372e-01,  ...,  4.1279e-01,\n",
       "            6.9049e-01, -1.1935e+00]],\n",
       "\n",
       "         [[ 8.0815e-01,  4.3602e-02, -2.4077e-01,  ..., -2.4817e-01,\n",
       "           -2.5356e-01, -2.7974e-01],\n",
       "          [-4.3514e-01,  4.2535e-01,  5.5833e-01,  ..., -9.3846e-01,\n",
       "           -7.7287e-02, -2.6221e-01],\n",
       "          [-2.1967e-02, -2.8470e-01,  3.9343e-01,  ..., -1.0171e+00,\n",
       "           -2.4531e-01, -1.1631e+00],\n",
       "          ...,\n",
       "          [ 8.6767e-02, -3.7285e-02,  1.0647e+00,  ..., -2.9303e-01,\n",
       "           -1.7966e-01, -2.6104e-01],\n",
       "          [-2.9954e-02,  3.1925e-01,  4.3913e-01,  ..., -5.1741e-01,\n",
       "            7.6370e-02, -5.1213e-01],\n",
       "          [-1.3198e+00, -9.5477e-01, -4.0145e-01,  ..., -8.6596e-01,\n",
       "           -1.2601e+00, -2.1561e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.4843e-02, -7.4396e-02,  5.8557e-03,  ...,  6.7559e-02,\n",
       "           -5.5559e-03, -1.7136e-02],\n",
       "          [ 5.5277e-01, -9.0972e-01,  3.2687e-01,  ..., -2.3805e-01,\n",
       "           -8.3028e-01,  6.0128e-01],\n",
       "          [ 3.3291e-01, -8.9779e-01,  3.8714e-01,  ..., -2.3305e-01,\n",
       "            6.8971e-02,  1.0322e-01],\n",
       "          ...,\n",
       "          [ 5.2275e-01, -6.2823e-01, -3.6024e-01,  ..., -1.7918e-01,\n",
       "           -5.4853e-01, -3.6071e-01],\n",
       "          [ 8.1788e-01, -5.9303e-01,  1.6346e-01,  ...,  2.4461e-02,\n",
       "           -3.9109e-01,  1.4335e-01],\n",
       "          [-3.6072e-01, -7.3018e-01,  1.4622e-01,  ...,  6.0637e-01,\n",
       "            1.7835e-01,  7.4398e-02]],\n",
       "\n",
       "         [[-2.5402e-02,  3.7893e-02, -4.6695e-03,  ..., -3.2933e-02,\n",
       "            7.8297e-03,  5.1288e-04],\n",
       "          [-2.1833e-01,  5.4492e-01, -5.5156e-01,  ..., -4.6149e-01,\n",
       "           -5.9172e-01, -4.7250e-01],\n",
       "          [ 7.9281e-01, -4.7352e-01, -9.4185e-01,  ..., -5.2474e-01,\n",
       "           -9.3760e-01, -1.0509e+00],\n",
       "          ...,\n",
       "          [-5.2136e-01,  3.7949e-01, -4.6862e-01,  ..., -8.6698e-02,\n",
       "           -7.0732e-01, -8.3236e-02],\n",
       "          [ 3.5340e-01, -2.1854e-01, -2.0469e-01,  ..., -1.0289e+00,\n",
       "            8.7302e-03, -2.4971e-01],\n",
       "          [ 2.0141e-01,  2.7480e-01,  8.0616e-02,  ..., -1.2972e-01,\n",
       "           -4.9792e-01, -1.2243e-01]],\n",
       "\n",
       "         [[ 3.0711e-02, -1.4473e-01,  2.8596e-02,  ...,  1.5525e-01,\n",
       "           -2.2122e-02,  4.3278e-02],\n",
       "          [ 5.3030e-02,  9.9054e-01,  4.8896e-02,  ..., -1.3159e+00,\n",
       "            6.7292e-01, -1.5558e-01],\n",
       "          [-5.0034e-01,  1.1845e+00, -1.7428e-01,  ..., -1.0273e+00,\n",
       "            3.8796e-02, -3.2121e-01],\n",
       "          ...,\n",
       "          [-3.1277e-01,  8.7858e-01,  1.7221e-01,  ..., -6.4866e-01,\n",
       "            3.6482e-01, -5.0587e-01],\n",
       "          [ 1.1159e-01, -4.9575e-02, -2.8313e-01,  ..., -5.0725e-01,\n",
       "            1.0340e-01, -1.3494e+00],\n",
       "          [-4.8777e-01,  7.0936e-01, -1.0381e+00,  ..., -8.5879e-02,\n",
       "            6.7394e-02,  2.6530e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 5.7740e-03, -1.9457e-02,  9.6003e-02,  ...,  3.1425e+01,\n",
       "           -5.7244e+01,  4.3643e+01],\n",
       "          [-4.2592e-01, -3.5357e-01,  1.6953e+00,  ...,  3.1068e+01,\n",
       "           -5.6970e+01,  4.4043e+01],\n",
       "          [-9.0329e-01, -2.0597e-01,  2.2872e-01,  ...,  3.1856e+01,\n",
       "           -5.7179e+01,  4.3789e+01],\n",
       "          ...,\n",
       "          [-3.7827e-01, -9.8203e-01,  1.8427e+00,  ...,  3.0759e+01,\n",
       "           -5.7419e+01,  4.2677e+01],\n",
       "          [ 6.1687e-01, -1.0513e+00,  4.1498e-01,  ...,  3.0935e+01,\n",
       "           -5.7503e+01,  4.2689e+01],\n",
       "          [ 6.3978e-01, -1.2779e+00, -1.2676e+00,  ...,  3.0831e+01,\n",
       "           -5.7017e+01,  4.3480e+01]],\n",
       "\n",
       "         [[ 8.5602e-02,  8.7374e-02, -1.2430e-01,  ...,  4.2317e+01,\n",
       "           -4.8539e+01, -4.7844e+01],\n",
       "          [-3.2120e-01,  2.4669e+00,  2.4977e+00,  ...,  4.2564e+01,\n",
       "           -4.9022e+01, -4.6973e+01],\n",
       "          [ 1.4292e+00,  1.6598e+00,  1.0496e+00,  ...,  4.2522e+01,\n",
       "           -4.9982e+01, -4.7482e+01],\n",
       "          ...,\n",
       "          [-6.5927e-01,  2.5414e+00,  3.9442e+00,  ...,  4.3913e+01,\n",
       "           -5.0505e+01, -4.7701e+01],\n",
       "          [-4.0915e+00,  3.5487e+00,  5.0519e+00,  ...,  4.4676e+01,\n",
       "           -4.9799e+01, -4.7864e+01],\n",
       "          [-1.4160e+00,  3.9931e+00,  4.4381e+00,  ...,  4.3405e+01,\n",
       "           -4.8946e+01, -4.6999e+01]],\n",
       "\n",
       "         [[ 1.2779e-03,  2.0505e-01,  1.0663e-01,  ...,  3.6052e+01,\n",
       "            4.4944e+01, -3.0622e+01],\n",
       "          [ 6.0169e-01,  2.7652e+00,  2.9183e-01,  ...,  3.5680e+01,\n",
       "            4.8336e+01, -3.2355e+01],\n",
       "          [-1.1540e+00,  1.9243e+00,  2.4675e-01,  ...,  3.3979e+01,\n",
       "            4.8182e+01, -3.0960e+01],\n",
       "          ...,\n",
       "          [ 1.4403e-01,  1.0786e+00,  3.6920e-01,  ...,  3.3356e+01,\n",
       "            4.8841e+01, -3.1038e+01],\n",
       "          [ 2.2875e-01,  8.4751e-01,  5.0905e-02,  ...,  3.5467e+01,\n",
       "            4.9588e+01, -3.0007e+01],\n",
       "          [ 2.0616e+00,  7.8291e-01, -6.7231e-01,  ...,  3.5222e+01,\n",
       "            5.0046e+01, -2.9875e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.5512e-01,  2.2030e-01,  7.5453e-02,  ..., -4.1742e+01,\n",
       "            3.7421e+01, -2.2712e+01],\n",
       "          [ 1.0069e-01, -1.4500e+00, -1.7302e+00,  ..., -4.0792e+01,\n",
       "            3.6430e+01, -2.2712e+01],\n",
       "          [-1.5088e+00, -1.7490e+00, -1.7586e+00,  ..., -4.0819e+01,\n",
       "            3.6155e+01, -2.1941e+01],\n",
       "          ...,\n",
       "          [-7.7194e-01, -2.4134e-01, -1.3711e+00,  ..., -4.0761e+01,\n",
       "            3.6967e+01, -2.3393e+01],\n",
       "          [ 1.5956e+00, -1.7662e+00, -1.9635e+00,  ..., -3.9973e+01,\n",
       "            3.7393e+01, -2.2530e+01],\n",
       "          [-2.9253e-01, -9.2030e-01, -2.3768e+00,  ..., -4.0572e+01,\n",
       "            3.6730e+01, -2.1570e+01]],\n",
       "\n",
       "         [[ 1.2481e-01, -7.2139e-02,  4.0927e-02,  ...,  5.6914e+01,\n",
       "            3.0602e+01, -1.4447e+01],\n",
       "          [-8.5217e-01, -8.0001e-01, -1.0424e+00,  ...,  5.8407e+01,\n",
       "            3.0280e+01, -1.8306e+01],\n",
       "          [ 4.1620e-01, -5.6097e-01, -2.3863e-01,  ...,  5.8088e+01,\n",
       "            3.0060e+01, -1.7800e+01],\n",
       "          ...,\n",
       "          [-1.2360e+00, -7.7378e-01, -8.7845e-01,  ...,  5.8475e+01,\n",
       "            3.0740e+01, -2.1412e+01],\n",
       "          [-6.1592e-01, -1.3089e+00, -1.8299e+00,  ...,  5.8244e+01,\n",
       "            3.1393e+01, -2.0268e+01],\n",
       "          [ 5.0836e-01, -1.7604e-01, -7.3097e-01,  ...,  5.7989e+01,\n",
       "            3.0674e+01, -2.1859e+01]],\n",
       "\n",
       "         [[-1.2680e-02, -2.7521e-01, -1.3797e-01,  ..., -5.1110e+01,\n",
       "            4.1553e+01, -4.4628e+01],\n",
       "          [-7.2093e-01,  1.9609e+00,  5.8421e-01,  ..., -5.0197e+01,\n",
       "            4.1021e+01, -4.1888e+01],\n",
       "          [-4.5977e-01,  5.3053e-01, -1.2716e+00,  ..., -5.0955e+01,\n",
       "            4.1148e+01, -4.2978e+01],\n",
       "          ...,\n",
       "          [ 2.9935e+00,  5.5121e-01, -1.3379e+00,  ..., -5.1122e+01,\n",
       "            4.2364e+01, -4.4583e+01],\n",
       "          [-3.1236e-01,  1.7452e+00, -5.4695e-01,  ..., -5.0752e+01,\n",
       "            4.2410e+01, -4.4064e+01],\n",
       "          [-2.1098e+00,  1.9723e+00, -2.4370e+00,  ..., -5.1148e+01,\n",
       "            4.1003e+01, -4.4488e+01]]]], device='cuda:0',\n",
       "       grad_fn=<CatBackward0>), tensor([[[[-1.9302e-02,  1.2400e-02, -7.8329e-02,  ...,  6.2845e-02,\n",
       "            1.4214e-02,  6.8186e-02],\n",
       "          [-2.6925e-01,  3.5780e-01, -1.3786e+00,  ..., -1.0351e+00,\n",
       "           -2.3175e-01,  1.8557e-01],\n",
       "          [ 1.9895e-01, -1.0407e+00, -1.1808e+00,  ..., -4.1236e-01,\n",
       "           -4.3651e-01, -4.9986e-01],\n",
       "          ...,\n",
       "          [-3.6949e-01, -6.8997e-01, -2.3451e-01,  ...,  7.0889e-02,\n",
       "            1.0384e-01, -1.3361e+00],\n",
       "          [-6.1606e-02, -1.9493e-01,  9.4996e-01,  ...,  7.7879e-02,\n",
       "           -3.6509e-01,  4.1114e-01],\n",
       "          [-5.3376e-01, -1.2495e+00, -5.1061e-01,  ..., -9.9890e-02,\n",
       "           -1.0125e+00, -6.4389e-01]],\n",
       "\n",
       "         [[-4.8262e-03,  6.8683e-04, -6.2262e-03,  ..., -6.5207e-02,\n",
       "            9.4956e-05,  3.0271e-02],\n",
       "          [-8.7877e-01,  8.9715e-01, -1.0566e-01,  ..., -4.6221e-01,\n",
       "            1.0522e-01,  7.8399e-01],\n",
       "          [-1.9083e-01,  1.1171e+00, -3.8521e-01,  ...,  3.6606e-01,\n",
       "            3.7781e-01,  6.1369e-01],\n",
       "          ...,\n",
       "          [-1.2949e-01, -2.6668e-01,  8.4750e-01,  ..., -3.8291e-01,\n",
       "           -1.0254e+00,  2.4014e-01],\n",
       "          [ 3.2590e-01, -1.2134e+00,  8.0283e-01,  ..., -1.0661e+00,\n",
       "           -6.9951e-01,  3.6843e-01],\n",
       "          [ 9.5678e-01, -1.6805e+00,  1.4347e+00,  ...,  1.6949e-01,\n",
       "           -7.1117e-01,  1.1082e-01]],\n",
       "\n",
       "         [[-1.3623e-02,  8.1179e-02,  3.7965e-02,  ...,  9.7007e-03,\n",
       "           -3.6843e-02,  4.2198e-02],\n",
       "          [-2.9723e-01,  9.1134e-02,  2.5984e-01,  ...,  1.8366e-01,\n",
       "           -1.8137e-01,  9.5082e-01],\n",
       "          [ 1.2542e-01,  1.9017e-01, -4.2724e-01,  ...,  2.9632e-02,\n",
       "           -5.4916e-01,  1.3442e-01],\n",
       "          ...,\n",
       "          [ 1.6029e-01,  7.6828e-02,  2.0833e-01,  ..., -8.3139e-01,\n",
       "           -2.3325e-01,  3.5617e-01],\n",
       "          [-2.4843e-01,  2.1538e-01,  1.7159e-01,  ..., -2.0235e-01,\n",
       "           -1.5236e+00,  1.4326e+00],\n",
       "          [-5.6000e-02, -8.6526e-02, -1.0236e+00,  ..., -1.7240e-01,\n",
       "           -7.2063e-01,  1.1488e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.5155e-01,  9.6271e-03, -2.2948e-01,  ...,  5.3521e-02,\n",
       "           -8.5677e-01,  5.6062e-02],\n",
       "          [ 4.7224e-01, -4.3672e-01,  3.8243e-01,  ..., -6.8833e-02,\n",
       "           -2.3404e-02, -7.0849e-01],\n",
       "          [ 3.5693e-01, -4.4134e-02, -4.0672e-01,  ..., -3.2786e-01,\n",
       "           -4.8902e-01, -3.8196e-01],\n",
       "          ...,\n",
       "          [-1.9667e-01, -1.0057e+00, -1.1763e+00,  ..., -1.8866e-01,\n",
       "           -5.3453e-01,  6.2403e-01],\n",
       "          [ 1.3127e+00, -3.7916e-01, -1.8280e+00,  ...,  4.1070e-01,\n",
       "           -8.1737e-01,  1.0894e+00],\n",
       "          [-3.9076e-02, -7.0336e-01, -4.2087e-01,  ...,  8.2008e-01,\n",
       "           -1.9374e-01,  7.7218e-01]],\n",
       "\n",
       "         [[-4.4291e-02,  7.1356e-03, -7.4920e-02,  ..., -2.1442e-01,\n",
       "            3.2307e-03, -2.4665e-02],\n",
       "          [ 4.8285e-01, -5.0945e-01, -2.9320e-01,  ...,  9.3459e-01,\n",
       "            1.0752e+00,  8.9909e-01],\n",
       "          [-7.0584e-01, -1.5108e-01, -2.2155e-01,  ..., -9.3434e-01,\n",
       "            5.5950e-01,  1.9820e+00],\n",
       "          ...,\n",
       "          [ 3.3780e-01, -4.8967e-01, -7.6330e-01,  ...,  6.7422e-01,\n",
       "            3.0721e-01, -3.8649e-01],\n",
       "          [-9.2987e-02, -1.5263e+00,  1.4350e+00,  ..., -1.9187e+00,\n",
       "            8.9153e-01, -3.2969e-01],\n",
       "          [ 1.7146e+00, -2.8009e+00, -4.1144e-02,  ..., -1.5753e-01,\n",
       "            9.4261e-01,  5.6793e-01]],\n",
       "\n",
       "         [[ 2.2859e-01, -6.7493e-01,  4.8052e-02,  ...,  7.5491e-02,\n",
       "            2.5554e-04, -1.2168e-01],\n",
       "          [-7.1473e-02, -9.9078e-01,  6.7923e-01,  ...,  1.5682e+00,\n",
       "           -1.0356e+00,  6.1177e-01],\n",
       "          [ 9.5413e-01, -1.6802e-01,  7.1720e-01,  ...,  7.7941e-01,\n",
       "           -9.1167e-01,  5.5950e-02],\n",
       "          ...,\n",
       "          [-1.8973e+00,  4.3721e-02, -1.8270e-01,  ...,  1.0534e+00,\n",
       "            8.5106e-01,  2.8194e-01],\n",
       "          [-8.0398e-01, -8.9690e-01,  4.7138e-01,  ...,  1.1442e+00,\n",
       "            1.6477e+00,  1.0159e+00],\n",
       "          [-5.2408e-01, -2.4583e-01, -3.2313e-01,  ..., -1.3774e-01,\n",
       "            2.0286e+00,  5.2460e-01]]]], device='cuda:0',\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 2.9442e-01, -3.7973e-02,  2.4093e-01,  ..., -5.8684e+01,\n",
       "            5.6767e+01, -5.9554e+01],\n",
       "          [ 2.9108e+00,  3.3042e+00,  6.3522e+00,  ..., -5.8405e+01,\n",
       "            5.5409e+01, -5.9827e+01],\n",
       "          [ 8.5158e-01,  2.6736e+00,  9.8464e+00,  ..., -5.9169e+01,\n",
       "            5.6649e+01, -5.9260e+01],\n",
       "          ...,\n",
       "          [-1.9107e+00,  5.4418e+00,  9.5657e+00,  ..., -5.7656e+01,\n",
       "            5.7013e+01, -5.9178e+01],\n",
       "          [ 2.6555e+00,  5.5906e+00,  8.3140e+00,  ..., -5.7679e+01,\n",
       "            5.6297e+01, -5.8689e+01],\n",
       "          [ 2.5434e+00,  2.3238e+00,  4.1212e+00,  ..., -5.8050e+01,\n",
       "            5.7603e+01, -5.9973e+01]],\n",
       "\n",
       "         [[-1.6414e+00,  1.9390e+00, -1.7055e+00,  ..., -4.8319e+01,\n",
       "           -6.1119e+01, -5.0551e+01],\n",
       "          [-1.5522e+00,  5.9232e-01, -7.5221e-01,  ..., -4.7908e+01,\n",
       "           -6.1894e+01, -5.2199e+01],\n",
       "          [ 1.4683e+00, -6.7764e-01, -2.0448e+00,  ..., -4.5773e+01,\n",
       "           -6.1038e+01, -5.0995e+01],\n",
       "          ...,\n",
       "          [ 2.5657e+00,  8.2072e-01, -4.4851e+00,  ..., -4.7543e+01,\n",
       "           -6.1288e+01, -5.1494e+01],\n",
       "          [-2.3092e+00,  8.2838e-01, -2.2605e+00,  ..., -4.7160e+01,\n",
       "           -6.1875e+01, -5.2490e+01],\n",
       "          [-1.6623e+00,  2.2527e-01, -2.4372e+00,  ..., -4.9071e+01,\n",
       "           -6.0903e+01, -4.9641e+01]],\n",
       "\n",
       "         [[-4.8148e-01,  5.2321e-01, -2.7954e-01,  ...,  5.3662e+01,\n",
       "           -6.3729e+01,  5.3709e+01],\n",
       "          [-3.0384e+00,  3.6784e+00, -1.9536e+00,  ...,  5.5946e+01,\n",
       "           -6.2996e+01,  5.4262e+01],\n",
       "          [-1.4428e+00,  2.3532e+00, -9.6751e+00,  ...,  5.0633e+01,\n",
       "           -6.3962e+01,  5.6495e+01],\n",
       "          ...,\n",
       "          [ 1.8528e+00,  1.3730e+01, -1.3170e+00,  ...,  5.4569e+01,\n",
       "           -6.3193e+01,  5.4719e+01],\n",
       "          [-9.0534e+00,  1.2149e+01, -1.4550e+00,  ...,  5.6935e+01,\n",
       "           -6.3398e+01,  5.5927e+01],\n",
       "          [-1.0384e+00,  3.7556e+00, -1.4343e+00,  ...,  4.8938e+01,\n",
       "           -6.3685e+01,  5.1405e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.9194e-01, -8.2681e-02,  2.0959e-01,  ..., -4.4088e+01,\n",
       "           -3.7453e+01,  4.2620e+01],\n",
       "          [-4.3260e+00, -3.3536e+00, -8.1918e-01,  ..., -4.3462e+01,\n",
       "           -3.9767e+01,  4.2352e+01],\n",
       "          [-5.2496e-01, -1.7946e+00, -3.1519e+00,  ..., -4.3223e+01,\n",
       "           -3.5464e+01,  4.3408e+01],\n",
       "          ...,\n",
       "          [ 4.2422e+00, -5.6003e+00, -1.9321e+00,  ..., -4.4450e+01,\n",
       "           -3.7142e+01,  4.1941e+01],\n",
       "          [-9.0375e-01, -2.8011e+00, -1.9624e+00,  ..., -4.3669e+01,\n",
       "           -3.7931e+01,  4.3473e+01],\n",
       "          [-5.0669e-01, -1.1857e+00,  9.8910e-01,  ..., -4.3562e+01,\n",
       "           -3.9443e+01,  4.1734e+01]],\n",
       "\n",
       "         [[-3.3726e-02,  1.6442e+00,  6.5675e+00,  ..., -5.0779e+01,\n",
       "           -4.9139e+01, -5.3166e+01],\n",
       "          [-1.3821e+00,  1.9827e+00,  2.6529e+00,  ..., -5.0426e+01,\n",
       "           -4.8843e+01, -5.3459e+01],\n",
       "          [ 1.4027e+00,  1.4126e+00,  4.2420e+00,  ..., -4.6975e+01,\n",
       "           -4.6954e+01, -5.3014e+01],\n",
       "          ...,\n",
       "          [ 3.4018e+00, -5.5466e-01,  7.4788e+00,  ..., -4.9046e+01,\n",
       "           -4.5354e+01, -5.2789e+01],\n",
       "          [-3.0131e+00,  4.7240e-01,  6.1623e+00,  ..., -4.9759e+01,\n",
       "           -4.6628e+01, -5.2793e+01],\n",
       "          [-2.1084e+00, -7.0559e-01,  3.1759e+00,  ..., -4.5396e+01,\n",
       "           -4.7458e+01, -5.1895e+01]],\n",
       "\n",
       "         [[ 3.8823e+00,  5.9286e-01,  3.6252e+00,  ..., -5.7009e+01,\n",
       "           -5.5649e+01,  5.8647e+01],\n",
       "          [-1.0254e+00,  2.6120e+00,  9.3233e+00,  ..., -5.7429e+01,\n",
       "           -5.3741e+01,  5.8932e+01],\n",
       "          [-1.0023e+01,  6.1556e+00,  7.6123e+00,  ..., -5.7635e+01,\n",
       "           -5.6293e+01,  5.8935e+01],\n",
       "          ...,\n",
       "          [ 6.8178e+00,  3.6400e+00,  2.5625e+00,  ..., -5.5713e+01,\n",
       "           -5.4219e+01,  5.8429e+01],\n",
       "          [ 1.4360e+01,  8.5381e+00,  4.5459e+00,  ..., -5.6903e+01,\n",
       "           -5.3980e+01,  5.7855e+01],\n",
       "          [ 4.4854e+00,  2.0297e+00,  4.8191e+00,  ..., -5.7238e+01,\n",
       "           -5.5195e+01,  5.8723e+01]]]], device='cuda:0',\n",
       "       grad_fn=<CatBackward0>), tensor([[[[ 0.0965,  0.0910,  0.0057,  ..., -0.0212,  0.0047,  0.0228],\n",
       "          [-0.5165, -0.1562,  0.3777,  ...,  0.0678, -0.7783, -0.5479],\n",
       "          [ 0.0222, -0.5048,  0.3595,  ...,  0.4653,  0.5596, -0.8753],\n",
       "          ...,\n",
       "          [ 0.3132,  0.5457,  0.9095,  ...,  0.2896, -0.2590, -0.7021],\n",
       "          [ 0.5907,  0.3680, -0.6579,  ...,  0.6313, -0.6032,  0.7268],\n",
       "          [ 0.4232,  0.4213, -1.1176,  ...,  0.3245,  0.5311, -1.1864]],\n",
       "\n",
       "         [[-0.0412, -0.3725, -0.6959,  ...,  0.2590,  0.1310, -0.1996],\n",
       "          [ 0.0229,  0.2513, -2.5533,  ...,  0.7382,  0.2243,  0.0233],\n",
       "          [-0.3569, -0.0610, -2.1542,  ...,  0.7161,  0.0872, -0.5277],\n",
       "          ...,\n",
       "          [-0.7383, -0.6974, -0.7926,  ...,  0.2297, -0.4149,  0.8480],\n",
       "          [-0.8042,  0.1985, -0.4455,  ...,  1.1511,  0.0808,  0.6081],\n",
       "          [-0.3627, -0.5969, -0.3135,  ...,  0.8310, -0.2334,  0.1901]],\n",
       "\n",
       "         [[-0.1010,  0.0746, -0.0268,  ..., -0.0944,  0.0873, -0.0801],\n",
       "          [ 0.3779,  0.1688, -0.2700,  ..., -0.1474, -0.1153, -0.5072],\n",
       "          [ 0.0548,  0.4485, -1.3553,  ..., -0.3221,  1.1968, -0.4269],\n",
       "          ...,\n",
       "          [-0.0957, -0.3024,  0.4218,  ...,  0.4958,  0.0678,  0.7877],\n",
       "          [ 0.0957, -0.2091, -0.2010,  ...,  0.4152,  0.9488,  1.1074],\n",
       "          [ 0.7535, -0.5063, -0.8501,  ...,  1.8360,  0.4462,  0.7408]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0399, -0.1867, -0.1078,  ..., -0.0048,  0.0579, -0.0107],\n",
       "          [-0.2433, -0.9312, -0.6221,  ...,  0.5661,  0.1796, -0.1242],\n",
       "          [ 0.3127,  0.0406,  0.2284,  ..., -0.4553, -0.0862,  0.4346],\n",
       "          ...,\n",
       "          [ 1.5267,  0.0999,  0.5417,  ..., -0.7952,  0.1928,  0.2132],\n",
       "          [ 1.4785,  0.2854, -0.3542,  ..., -1.0290, -0.1598, -1.4042],\n",
       "          [-0.0169, -0.2184, -1.4013,  ..., -0.6813,  0.5200,  0.6640]],\n",
       "\n",
       "         [[-1.3114, -0.0270, -0.2623,  ..., -0.2205, -0.7142,  0.2124],\n",
       "          [-0.6562,  0.0820, -0.1054,  ...,  0.6497, -1.0529, -1.0882],\n",
       "          [-1.1173,  0.2098, -0.0493,  ...,  0.6206, -0.8228, -0.2677],\n",
       "          ...,\n",
       "          [-0.2139,  0.8194, -0.1481,  ...,  0.3746, -0.7032,  0.8492],\n",
       "          [-0.3168, -0.4345,  0.0427,  ...,  0.2911,  0.1442,  0.7199],\n",
       "          [-0.8388,  0.4793,  0.8622,  ...,  0.3532,  0.2471,  0.9822]],\n",
       "\n",
       "         [[ 0.1156,  0.0753,  0.4481,  ..., -0.0492,  0.0081,  0.2935],\n",
       "          [-0.0460, -0.4041, -0.3067,  ..., -0.2946, -0.2748, -0.4262],\n",
       "          [-0.2943, -0.4486,  0.4199,  ..., -0.0655, -0.5272,  0.5166],\n",
       "          ...,\n",
       "          [-0.2009, -0.1892, -0.7889,  ...,  1.0175, -0.0461, -0.0276],\n",
       "          [ 0.2446, -0.3066, -1.5816,  ...,  0.3963,  1.2286, -0.2699],\n",
       "          [ 0.5106, -0.8748, -0.2855,  ...,  1.2705, -0.1759, -1.2978]]]],\n",
       "       device='cuda:0', grad_fn=<PermuteBackward0>))), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_perplexity(dataset_index):\n",
    "tokens = dataset.iloc[0][\"tokens\"]\n",
    "text = pythia_tokenizer.decode(tokens)\n",
    "model_inputs = pythia_tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "target_ids = model_inputs.input_ids.clone().to(device)\n",
    "# pythia_model.generate(**model_inputs, return_dict_in_generate=True, output_scores=True)\n",
    "pythia_model(**model_inputs, labels=target_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using sep_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_1438151/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1396924949.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">22</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19 â”‚   â”‚   </span>losses = np.empty(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(tokens))                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20 â”‚   â”‚   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                               <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>22 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span>output = pythia_model(**model_inputs, labels=target_ids)                        <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 â”‚   â”‚   â”‚   </span>loss = output.loss                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24 â”‚   â”‚   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25 â”‚   â”‚   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(losses)                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mchorse/.local/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 â”‚   â”‚   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 â”‚   â”‚   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 â”‚   â”‚   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mchorse/.local/lib/python3.9/site-packages/transformers/models/gpt_neox/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt_neox.</span> <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">675</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">672 â”‚   â”‚   â”‚   </span>shift_logits = lm_logits[:, :-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, :].contiguous()                               <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">673 â”‚   â”‚   â”‚   </span>labels = labels[:, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:].contiguous()                                            <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">674 â”‚   â”‚   â”‚   </span>loss_fct = CrossEntropyLoss()                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>675 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span>lm_loss = loss_fct(shift_logits.view(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, shift_logits.size(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)), labels.view   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">676 â”‚   â”‚   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">677 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> return_dict:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">678 â”‚   â”‚   â”‚   </span>output = (lm_logits,) + outputs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:]                                            <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mchorse/.local/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1127 â”‚   â”‚   # this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>1130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1131 â”‚   â”‚   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 â”‚   â”‚   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mchorse/.local/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">loss.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1164</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>        <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1161 â”‚   â”‚   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.label_smoothing = label_smoothing                                            <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1162 â”‚   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1163 â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor, target: Tensor) -&gt; Tensor:                           <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>1164 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> F.cross_entropy(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, weight=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight,                         <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1165 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      </span>ignore_index=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ignore_index, reduction=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.reduction,  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1166 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      </span>label_smoothing=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.label_smoothing)                      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1167 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/mchorse/.local/lib/python3.9/site-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3014</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cross_entropy</span>    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3011 â”‚   â”‚   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3012 â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> size_average <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> reduce <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3013 â”‚   â”‚   </span>reduction = _Reduction.legacy_get_string(size_average, reduce)                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>3014 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">â”‚   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch._C._nn.cross_entropy_loss(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, target, weight, _Reduction.get_enum(re  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3015 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3016 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3017 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">binary_cross_entropy</span>(                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Expected input batch_size <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span> to match target batch_size <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/tmp/ipykernel_1438151/\u001b[0m\u001b[1;33m1396924949.py\u001b[0m:\u001b[94m22\u001b[0m in \u001b[92m<module>\u001b[0m                                              \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mlosses = np.empty(\u001b[96mlen\u001b[0m(tokens))                                                      \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m20 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m                                                                                    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m21 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                               \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m22 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0moutput = pythia_model(**model_inputs, labels=target_ids)                        \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mloss = output.loss                                                              \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m24 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m                                                                                    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m25 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[96mprint\u001b[0m(losses)                                                                       \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/home/mchorse/.local/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1130 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/home/mchorse/.local/lib/python3.9/site-packages/transformers/models/gpt_neox/\u001b[0m\u001b[1;33mmodeling_gpt_neox.\u001b[0m \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m675\u001b[0m in \u001b[92mforward\u001b[0m                                                                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m672 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mshift_logits = lm_logits[:, :-\u001b[94m1\u001b[0m, :].contiguous()                               \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m673 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mlabels = labels[:, \u001b[94m1\u001b[0m:].contiguous()                                            \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m674 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0mloss_fct = CrossEntropyLoss()                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m675 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0mlm_loss = loss_fct(shift_logits.view(-\u001b[94m1\u001b[0m, shift_logits.size(-\u001b[94m1\u001b[0m)), labels.view   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m676 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m                                                                                   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m677 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m return_dict:                                                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m678 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   \u001b[0moutput = (lm_logits,) + outputs[\u001b[94m1\u001b[0m:]                                            \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/home/mchorse/.local/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1130\u001b[0m in \u001b[92m_call_impl\u001b[0m   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1127 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1130 \u001b[2mâ”‚   â”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1131 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/home/mchorse/.local/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mloss.py\u001b[0m:\u001b[94m1164\u001b[0m in \u001b[92mforward\u001b[0m        \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1161 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m\u001b[96mself\u001b[0m.label_smoothing = label_smoothing                                            \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1162 \u001b[0m\u001b[2mâ”‚   \u001b[0m                                                                                      \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1163 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor, target: Tensor) -> Tensor:                           \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1164 \u001b[2mâ”‚   â”‚   \u001b[0m\u001b[94mreturn\u001b[0m F.cross_entropy(\u001b[96minput\u001b[0m, target, weight=\u001b[96mself\u001b[0m.weight,                         \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1165 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      \u001b[0mignore_index=\u001b[96mself\u001b[0m.ignore_index, reduction=\u001b[96mself\u001b[0m.reduction,  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1166 \u001b[0m\u001b[2mâ”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚      \u001b[0mlabel_smoothing=\u001b[96mself\u001b[0m.label_smoothing)                      \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m1167 \u001b[0m                                                                                          \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[2;33m/home/mchorse/.local/lib/python3.9/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m3014\u001b[0m in \u001b[92mcross_entropy\u001b[0m    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m3011 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0m)                                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m3012 \u001b[0m\u001b[2mâ”‚   \u001b[0m\u001b[94mif\u001b[0m size_average \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m reduce \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m3013 \u001b[0m\u001b[2mâ”‚   â”‚   \u001b[0mreduction = _Reduction.legacy_get_string(size_average, reduce)                    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m3014 \u001b[2mâ”‚   \u001b[0m\u001b[94mreturn\u001b[0m torch._C._nn.cross_entropy_loss(\u001b[96minput\u001b[0m, target, weight, _Reduction.get_enum(re  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m3015 \u001b[0m                                                                                          \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m3016 \u001b[0m                                                                                          \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m3017 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mbinary_cross_entropy\u001b[0m(                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mExpected input batch_size \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m to match target batch_size \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sequence_record in dataset[0:1].iterrows():\n",
    "    pile_index = sequence_record[1][\"index\"]\n",
    "    tokens = sequence_record[1][\"tokens\"]\n",
    "\n",
    "    for token_index, true_token in enumerate(tokens):\n",
    "        if token_index == 0:\n",
    "            continue\n",
    "\n",
    "        context = tokens[0:token_index]\n",
    "        text = pythia_tokenizer.decode(context, return_tensors=\"pt\")\n",
    "        model_inputs = pythia_tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        true_context = tokens[0:token_index + 1]\n",
    "        true_text = pythia_tokenizer.decode(true_context, return_tensors=\"pt\")\n",
    "        target_ids = pythia_tokenizer(true_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "        \n",
    "        target_ids[:, :-token_index] = -100\n",
    "\n",
    "        losses = np.empty(len(tokens))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = pythia_model(**model_inputs, labels=target_ids)\n",
    "            loss = output.loss\n",
    "        \n",
    "        print(losses)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
