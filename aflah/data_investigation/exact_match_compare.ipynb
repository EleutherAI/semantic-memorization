{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandarallel import pandarallel\n",
    "import multiprocessing\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_and_compare(ls, k):\n",
    "    n = len(ls)\n",
    "    while n % k != 0:\n",
    "        n -= 1\n",
    "    to_break = ls[:n]\n",
    "    residual = ls[n:]\n",
    "    chunk_size = n // k\n",
    "    while len(residual) < chunk_size:\n",
    "        # split into chunks\n",
    "        chunks = [to_break[i:i + chunk_size] for i in range(0, len(to_break), chunk_size)]\n",
    "        chunksMatch = True\n",
    "        # compare all chunks to first chunk\n",
    "        for chunk in chunks[1:]:\n",
    "            if chunk != chunks[0]:\n",
    "                chunksMatch = False\n",
    "                break\n",
    "        if chunksMatch:\n",
    "            # compare residual to first chunk\n",
    "            if residual == chunks[0][:len(residual)]:\n",
    "                return chunks[0]\n",
    "        chunk_size -= 1\n",
    "        new_residual = to_break[chunk_size * k:]\n",
    "        to_break = to_break[:chunk_size * k]\n",
    "        residual = new_residual + residual\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_and_compare_wrapper(ls, start_k, end_k):\n",
    "    # end_k is inclusive\n",
    "    ls = list(ls)\n",
    "    for k in range(start_k, end_k + 1):\n",
    "        result = break_and_compare(ls, k)\n",
    "        if result:\n",
    "            return result, k\n",
    "    return [], -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "break_and_compare([1,2,3,4,1,2,3,4,1,2,3,4,1], k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 4], 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "break_and_compare_wrapper([1,2,3,4,1,2,3,4,1,2,3,4,1], start_k=2, end_k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pythia-70m.pkl',\n",
       " 'pythia-160m.pkl',\n",
       " 'pythia-410m.pkl',\n",
       " 'pythia-1b.pkl',\n",
       " 'pythia-1.4b.pkl',\n",
       " 'pythia-2.8b.pkl',\n",
       " 'pythia-6.9b.pkl',\n",
       " 'pythia-70m-deduped.pkl',\n",
       " 'pythia-160m-deduped.pkl',\n",
       " 'pythia-410m-deduped.pkl',\n",
       " 'pythia-1b-deduped.pkl',\n",
       " 'pythia-1.4b-deduped.pkl',\n",
       " 'pythia-2.8b-deduped.pkl',\n",
       " 'pythia-6.9b-deduped.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('../data')\n",
    "# choose files without 'lrs' or 'mrs' in the name\n",
    "files = [file for file in files if 'lrs' not in file and 'mrs' not in file]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_with_chunk_and_k(file):\n",
    "    df = pickle.load(open('../data/' + file, 'rb'))\n",
    "    df['chunk'] = df['chunk'].parallel_apply(lambda x: break_and_compare_wrapper(x, start_k=2, end_k=4))\n",
    "    # save df as pickle\n",
    "    pickle.dump(df, open('../data/' + file + \"_with_chunk_and_k\", 'wb'))\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pythia-70m.pkl\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    print(file)\n",
    "    get_df_with_chunk_and_k(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aflah_sem_mem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
