{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 48 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, ReadInstruction\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "# notebook tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 0% to 10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-deduped-pythia-random-sampled-ef6db9ddd170a4bc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/deduped_pythia_0_to_10.pkl\n",
      "Loading 10% to 20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-deduped-pythia-random-sampled-ef6db9ddd170a4bc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/deduped_pythia_10_to_20.pkl\n",
      "Loading 20% to 30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-deduped-pythia-random-sampled-ef6db9ddd170a4bc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/deduped_pythia_20_to_30.pkl\n",
      "Loading 30% to 40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-deduped-pythia-random-sampled-ef6db9ddd170a4bc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/deduped_pythia_30_to_40.pkl\n",
      "Loading 40% to 50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-deduped-pythia-random-sampled-ef6db9ddd170a4bc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/deduped_pythia_40_to_50.pkl\n",
      "Loading 50% to 60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-deduped-pythia-random-sampled-ef6db9ddd170a4bc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/deduped_pythia_50_to_60.pkl\n",
      "Loading 60% to 70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-deduped-pythia-random-sampled-ef6db9ddd170a4bc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/deduped_pythia_60_to_70.pkl\n",
      "Loading 70% to 80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-deduped-pythia-random-sampled-ef6db9ddd170a4bc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/deduped_pythia_70_to_80.pkl\n",
      "Loading 80% to 90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-deduped-pythia-random-sampled-ef6db9ddd170a4bc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/deduped_pythia_80_to_90.pkl\n",
      "Loading 90% to 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-deduped-pythia-random-sampled-ef6db9ddd170a4bc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/deduped_pythia_90_to_100.pkl\n"
     ]
    }
   ],
   "source": [
    "lower_pct = 0\n",
    "forgottens_records = None\n",
    "for upper_pct in range(10, 110, 10):\n",
    "    print(f\"Loading {lower_pct}% to {upper_pct}%\")\n",
    "    pile_tokens = load_dataset(\"EleutherAI/pile-deduped-pythia-random-sampled\", split=f'train[{lower_pct}%:{upper_pct}%]').to_pandas()\n",
    "    savename = f\"../data/deduped_pythia_{lower_pct}_to_{upper_pct}.pkl\"\n",
    "    print(f\"Saving to {savename}\")\n",
    "    pile_tokens.to_pickle(savename)\n",
    "    lower_pct = upper_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 0% to 10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-duped-pythia-random-sampled-6110a299bf16f914/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/duped_pythia_0_to_10.pkl\n",
      "Loading 10% to 20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-duped-pythia-random-sampled-6110a299bf16f914/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/duped_pythia_10_to_20.pkl\n",
      "Loading 20% to 30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-duped-pythia-random-sampled-6110a299bf16f914/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/duped_pythia_20_to_30.pkl\n",
      "Loading 30% to 40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-duped-pythia-random-sampled-6110a299bf16f914/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/duped_pythia_30_to_40.pkl\n",
      "Loading 40% to 50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-duped-pythia-random-sampled-6110a299bf16f914/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/duped_pythia_40_to_50.pkl\n",
      "Loading 50% to 60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-duped-pythia-random-sampled-6110a299bf16f914/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/duped_pythia_50_to_60.pkl\n",
      "Loading 60% to 70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-duped-pythia-random-sampled-6110a299bf16f914/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/duped_pythia_60_to_70.pkl\n",
      "Loading 70% to 80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-duped-pythia-random-sampled-6110a299bf16f914/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/duped_pythia_70_to_80.pkl\n",
      "Loading 80% to 90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-duped-pythia-random-sampled-6110a299bf16f914/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/duped_pythia_80_to_90.pkl\n",
      "Loading 90% to 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-duped-pythia-random-sampled-6110a299bf16f914/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ../data/duped_pythia_90_to_100.pkl\n"
     ]
    }
   ],
   "source": [
    "lower_pct = 0\n",
    "forgottens_records = None\n",
    "for upper_pct in range(10, 110, 10):\n",
    "    print(f\"Loading {lower_pct}% to {upper_pct}%\")\n",
    "    pile_tokens = load_dataset(\"EleutherAI/pile-duped-pythia-random-sampled\", split=f'train[{lower_pct}%:{upper_pct}%]').to_pandas()\n",
    "    savename = f\"../data/duped_pythia_{lower_pct}_to_{upper_pct}.pkl\"\n",
    "    print(f\"Saving to {savename}\")\n",
    "    pile_tokens.to_pickle(savename)\n",
    "    lower_pct = upper_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 0% to 10%\n",
      "Loading 10% to 20%\n",
      "Loading 20% to 30%\n",
      "Loading 30% to 40%\n",
      "Loading 40% to 50%\n",
      "Loading 50% to 60%\n",
      "Loading 60% to 70%\n",
      "Loading 70% to 80%\n",
      "Loading 80% to 90%\n",
      "Loading 90% to 100%\n"
     ]
    }
   ],
   "source": [
    "lower_pct = 0\n",
    "records = None\n",
    "for upper_pct in range(10, 110, 10):\n",
    "    print(f\"Loading {lower_pct}% to {upper_pct}%\")\n",
    "    pile_tokens = pd.read_pickle(f\"../data/deduped_pythia_{lower_pct}_to_{upper_pct}.pkl\")\n",
    "    if forgottens_records is None:\n",
    "        records = pile_tokens\n",
    "    else:\n",
    "        records = pd.concat([records, pile_tokens])\n",
    "    lower_pct = upper_pct\n",
    "\n",
    "records.to_pickle(\"../data/deduped_pythia.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 0% to 10%\n",
      "Loading 10% to 20%\n",
      "Loading 20% to 30%\n",
      "Loading 30% to 40%\n",
      "Loading 40% to 50%\n",
      "Loading 50% to 60%\n",
      "Loading 60% to 70%\n",
      "Loading 70% to 80%\n",
      "Loading 80% to 90%\n",
      "Loading 90% to 100%\n"
     ]
    }
   ],
   "source": [
    "lower_pct = 0\n",
    "records = None\n",
    "for upper_pct in range(10, 110, 10):\n",
    "    print(f\"Loading {lower_pct}% to {upper_pct}%\")\n",
    "    pile_tokens = pd.read_pickle(f\"../data/duped_pythia_{lower_pct}_to_{upper_pct}.pkl\")\n",
    "    if forgottens_records is None:\n",
    "        records = pile_tokens\n",
    "    else:\n",
    "        records = pd.concat([records, pile_tokens])\n",
    "    lower_pct = upper_pct\n",
    "\n",
    "records.to_pickle(\"../data/duped_pythia.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_dependency_length(sentence):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sentence)\n",
    "    ls_lengths = []\n",
    "    for token in doc:\n",
    "        for child in token.children:\n",
    "            distance = child.i - token.i\n",
    "            # print(f\"{token.text} --{child.dep_}--> {child.text}  (distance: {distance})\")\n",
    "            ls_lengths.append(abs(distance))\n",
    "    return np.mean(ls_lengths)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  'EleutherAI/pythia-70m-deduped',\n",
    "  revision='step3000',\n",
    ")\n",
    "def get_string(token_indices):\n",
    "    return tokenizer.decode(token_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-duped-pythia-random-sampled-6110a299bf16f914/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/aflah/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-deduped-pythia-random-sampled-ef6db9ddd170a4bc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "dataset_duped = load_dataset(\"EleutherAI/pile-duped-pythia-random-sampled\", split=\"train[:1%]\")\n",
    "dataset_deduped = load_dataset(\"EleutherAI/pile-deduped-pythia-random-sampled\", split=\"train[:1%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'is_memorized', 'index'],\n",
       "    num_rows: 50000\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_duped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_duped = dataset_duped.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_memorized\n",
       "False    49148\n",
       "True       852\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset_duped['is_memorized'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee63fb78da4d4ac9af4ebb1b1b7d191f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1042), Label(value='0 / 1042'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dataset_duped['first_64_tokens'] = df_dataset_duped['tokens'].parallel_apply(lambda x: x[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb75d71132964d4baea68009739eebc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1042), Label(value='0 / 1042'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dataset_duped['first_64_tokens_string'] = df_dataset_duped['first_64_tokens'].parallel_apply(get_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_first_64_tokens_string = df_dataset_duped['first_64_tokens_string'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1faafa96043d4e278531cbcbb82a5504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "ls_dependency_lengths = []\n",
    "# use a thread pool to parallelize the computation of dependency lengths\n",
    "with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "    futures = [executor.submit(get_avg_dependency_length, sent) for sent in ls_first_64_tokens_string]\n",
    "\n",
    "    # use tqdm to display a progress bar while the threads are running\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        ls_dependency_lengths.append(future.result())\n",
    "\n",
    "# print the list of average dependency lengths for each sentence\n",
    "print(ls_dependency_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sem_mem",
   "language": "python",
   "name": "sem_mem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
