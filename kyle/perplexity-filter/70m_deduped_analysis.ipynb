{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pythia 70M Deduped Perplexity Analysis\n",
    "\n",
    "This analysis was based off all the memorized and forgotten training sequences by the Pythia 70M dedupplicated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/miniconda3/envs/memorization/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset, ReadInstruction\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/kyle/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pythia-memorized-evals-623aaa371a33821a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 151M/151M [00:01<00:00, 82.8MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 74.7M/74.7M [00:00<00:00, 85.9MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 75.6M/75.6M [00:00<00:00, 93.6MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 75.8M/75.8M [00:00<00:00, 84.3MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 103M/103M [00:01<00:00, 54.6MB/s] \n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 104M/104M [00:01<00:00, 90.3MB/s] \n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 115M/115M [00:01<00:00, 91.8MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 133M/133M [00:01<00:00, 91.0MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 133M/133M [00:01<00:00, 90.6MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 45.7M/45.7M [00:00<00:00, 70.5MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 101M/101M [00:01<00:00, 87.4MB/s] \n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 101M/101M [00:01<00:00, 84.6MB/s] \n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 124M/124M [00:01<00:00, 92.0MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 125M/125M [00:01<00:00, 91.4MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 125M/125M [00:01<00:00, 87.1MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 89.0M/89.0M [00:01<00:00, 82.6MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 91.6M/91.6M [00:00<00:00, 93.2MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 91.9M/91.9M [00:01<00:00, 88.3MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 125M/125M [00:01<00:00, 89.1MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 126M/126M [00:01<00:00, 95.2MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 67.9M/67.9M [00:00<00:00, 85.6MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 68.1M/68.1M [00:00<00:00, 69.3MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 109M/109M [00:01<00:00, 91.3MB/s] \n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 110M/110M [00:01<00:00, 58.2MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 110M/110M [00:01<00:00, 89.8MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading data: 100%|██████████| 51.5M/51.5M [00:00<00:00, 72.3MB/s]\n",
      "Downloading data files: 100%|██████████| 16/16 [00:44<00:00,  2.77s/it]\n",
      "Extracting data files: 100%|██████████| 16/16 [00:00<00:00, 1169.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/kyle/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pythia-memorized-evals-623aaa371a33821a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>441</td>\n",
       "      <td>[5584, 4196, 1228, 187, 1036, 4, 209, 21723, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>447</td>\n",
       "      <td>[50262, 61, 2099, 92, 8861, 94, 187, 50262, 61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>792</td>\n",
       "      <td>[475, 50272, 953, 24781, 778, 320, 908, 281, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1539</td>\n",
       "      <td>[424, 380, 16101, 313, 433, 17889, 3104, 10, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1705</td>\n",
       "      <td>[3498, 2262, 2369, 40, 736, 13, 3956, 27, 21, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                             tokens\n",
       "0    441  [5584, 4196, 1228, 187, 1036, 4, 209, 21723, 2...\n",
       "1    447  [50262, 61, 2099, 92, 8861, 94, 187, 50262, 61...\n",
       "2    792  [475, 50272, 953, 24781, 778, 320, 908, 281, 1...\n",
       "3   1539  [424, 380, 16101, 313, 433, 17889, 3104, 10, 2...\n",
       "4   1705  [3498, 2262, 2369, 40, 736, 13, 3956, 27, 21, ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>441</td>\n",
       "      <td>2.935547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>447</td>\n",
       "      <td>1.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>792</td>\n",
       "      <td>3.556641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1539</td>\n",
       "      <td>3.658203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1705</td>\n",
       "      <td>9.070312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  perplexity\n",
       "0    441    2.935547\n",
       "1    447    1.734375\n",
       "2    792    3.556641\n",
       "3   1539    3.658203\n",
       "4   1705    9.070312"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 411448/411448 [00:11<00:00, 35174.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>441</td>\n",
       "      <td>2.935547</td>\n",
       "      <td>[5584, 4196, 1228, 187, 1036, 4, 209, 21723, 2...</td>\n",
       "      <td>/(-96))\\n16# *********************************...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>447</td>\n",
       "      <td>1.734375</td>\n",
       "      <td>[50262, 61, 2099, 92, 8861, 94, 187, 50262, 61...</td>\n",
       "      <td>\\usepackage{upgreek}\\n        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>792</td>\n",
       "      <td>3.556641</td>\n",
       "      <td>[475, 50272, 953, 24781, 778, 320, 908, 281, 1...</td>\n",
       "      <td>*      its contributors may be used to endors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1539</td>\n",
       "      <td>3.658203</td>\n",
       "      <td>[424, 380, 16101, 313, 433, 17889, 3104, 10, 2...</td>\n",
       "      <td>** The analytical (red dashed lines) and simul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1705</td>\n",
       "      <td>9.070312</td>\n",
       "      <td>[3498, 2262, 2369, 40, 736, 13, 3956, 27, 21, ...</td>\n",
       "      <td>px):noGrow,top:4dlu:noGrow,center:max(d;4px):n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411443</th>\n",
       "      <td>146431199</td>\n",
       "      <td>1.394531</td>\n",
       "      <td>[281, 320, 669, 8604, 60, 805, 431, 1019, 8402...</td>\n",
       "      <td>to be $\\documentclass[12pt]{minimal}\\n       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411444</th>\n",
       "      <td>146431278</td>\n",
       "      <td>2.791016</td>\n",
       "      <td>[588, 1705, 285, 8415, 634, 1895, 15, 30952, 3...</td>\n",
       "      <td>will come and solve your problem.&lt;!DOCTYPE ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411445</th>\n",
       "      <td>146431294</td>\n",
       "      <td>2.582031</td>\n",
       "      <td>[15468, 13, 50275, 13743, 13, 50275, 15220, 13...</td>\n",
       "      <td>134,   135,   136,   137,   138,   139,   140,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411446</th>\n",
       "      <td>146431588</td>\n",
       "      <td>3.103516</td>\n",
       "      <td>[27, 330, 14788, 10334, 14, 3429, 27, 577, 28,...</td>\n",
       "      <td>: C++; tab-width: 4; indent-tabs-mode: nil; c-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411447</th>\n",
       "      <td>146431592</td>\n",
       "      <td>4.062500</td>\n",
       "      <td>[1406, 485, 15, 23780, 300, 2473, 285, 12698, ...</td>\n",
       "      <td>ronome. Ventilatory and pulmonary gas exchange...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411448 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  perplexity   \n",
       "0             441    2.935547  \\\n",
       "1             447    1.734375   \n",
       "2             792    3.556641   \n",
       "3            1539    3.658203   \n",
       "4            1705    9.070312   \n",
       "...           ...         ...   \n",
       "411443  146431199    1.394531   \n",
       "411444  146431278    2.791016   \n",
       "411445  146431294    2.582031   \n",
       "411446  146431588    3.103516   \n",
       "411447  146431592    4.062500   \n",
       "\n",
       "                                                   tokens   \n",
       "0       [5584, 4196, 1228, 187, 1036, 4, 209, 21723, 2...  \\\n",
       "1       [50262, 61, 2099, 92, 8861, 94, 187, 50262, 61...   \n",
       "2       [475, 50272, 953, 24781, 778, 320, 908, 281, 1...   \n",
       "3       [424, 380, 16101, 313, 433, 17889, 3104, 10, 2...   \n",
       "4       [3498, 2262, 2369, 40, 736, 13, 3956, 27, 21, ...   \n",
       "...                                                   ...   \n",
       "411443  [281, 320, 669, 8604, 60, 805, 431, 1019, 8402...   \n",
       "411444  [588, 1705, 285, 8415, 634, 1895, 15, 30952, 3...   \n",
       "411445  [15468, 13, 50275, 13743, 13, 50275, 15220, 13...   \n",
       "411446  [27, 330, 14788, 10334, 14, 3429, 27, 577, 28,...   \n",
       "411447  [1406, 485, 15, 23780, 300, 2473, 285, 12698, ...   \n",
       "\n",
       "                                                     text  \n",
       "0       /(-96))\\n16# *********************************...  \n",
       "1                       \\usepackage{upgreek}\\n        ...  \n",
       "2        *      its contributors may be used to endors...  \n",
       "3       ** The analytical (red dashed lines) and simul...  \n",
       "4       px):noGrow,top:4dlu:noGrow,center:max(d;4px):n...  \n",
       "...                                                   ...  \n",
       "411443   to be $\\documentclass[12pt]{minimal}\\n       ...  \n",
       "411444   will come and solve your problem.<!DOCTYPE ht...  \n",
       "411445  134,   135,   136,   137,   138,   139,   140,...  \n",
       "411446  : C++; tab-width: 4; indent-tabs-mode: nil; c-...  \n",
       "411447  ronome. Ventilatory and pulmonary gas exchange...  \n",
       "\n",
       "[411448 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m-deduped\")\n",
    "memories_tokens = load_dataset(\"EleutherAI/pythia-memorized-evals\", split=\"deduped.70m\").to_pandas()[[\"index\", \"tokens\"]]\n",
    "memories_ppls = pd.read_csv(\"70m_4_27/memories_deduped_70m.csv\")\n",
    "display(memories_tokens.head())\n",
    "display(memories_ppls.head())\n",
    "all_memories_data = memories_ppls.join(memories_tokens.set_index(\"index\"), on=\"index\", how=\"inner\")\n",
    "all_memories_data[\"text\"] = all_memories_data[\"tokens\"].progress_apply(lambda x: tokenizer.decode(x))\n",
    "all_memories_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 468/468 [00:00<00:00, 198kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /root/.cache/huggingface/datasets/EleutherAI___parquet/EleutherAI--pile-deduped-pythia-random-sampled-ef6db9ddd170a4bc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data:  36%|███▌      | 2.12G/5.97G [02:12<03:59, 16.0MB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pile_tokens \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mEleutherAI/pile-deduped-pythia-random-sampled\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mto_pandas()\n\u001b[1;32m      2\u001b[0m pile_tokens\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/load.py:1791\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1788\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[1;32m   1790\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 1791\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[1;32m   1792\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1793\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1794\u001b[0m     verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m   1795\u001b[0m     try_from_hf_gcs\u001b[39m=\u001b[39;49mtry_from_hf_gcs,\n\u001b[1;32m   1796\u001b[0m     num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m   1797\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   1798\u001b[0m )\n\u001b[1;32m   1800\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1801\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[1;32m   1802\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[1;32m   1803\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/builder.py:891\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m         prepare_split_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_proc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_proc\n\u001b[0;32m--> 891\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[1;32m    892\u001b[0m         dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[1;32m    893\u001b[0m         verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[1;32m    894\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mprepare_split_kwargs,\n\u001b[1;32m    895\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_and_prepare_kwargs,\n\u001b[1;32m    896\u001b[0m     )\n\u001b[1;32m    897\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/builder.py:964\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m split_dict \u001b[39m=\u001b[39m SplitDict(dataset_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m    963\u001b[0m split_generators_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m--> 964\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_split_generators(dl_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msplit_generators_kwargs)\n\u001b[1;32m    966\u001b[0m \u001b[39m# Checksums verification\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[39mif\u001b[39;00m verification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS \u001b[39mand\u001b[39;00m dl_manager\u001b[39m.\u001b[39mrecord_checksums:\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/packaged_modules/parquet/parquet.py:34\u001b[0m, in \u001b[0;36mParquet._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdata_files:\n\u001b[1;32m     33\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAt least one data file must be specified, but got data_files=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdata_files\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m data_files \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39;49mdownload_and_extract(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mdata_files)\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_files, (\u001b[39mstr\u001b[39m, \u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m     36\u001b[0m     files \u001b[39m=\u001b[39m data_files\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/download/download_manager.py:564\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload_and_extract\u001b[39m(\u001b[39mself\u001b[39m, url_or_urls):\n\u001b[1;32m    549\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Download and extract given `url_or_urls`.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \n\u001b[1;32m    551\u001b[0m \u001b[39m    Is roughly equivalent to:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39m        extracted_path(s): `str`, extracted paths of given URL(s).\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 564\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload(url_or_urls))\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/download/download_manager.py:427\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    424\u001b[0m download_func \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download, download_config\u001b[39m=\u001b[39mdownload_config)\n\u001b[1;32m    426\u001b[0m start_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m--> 427\u001b[0m downloaded_path_or_paths \u001b[39m=\u001b[39m map_nested(\n\u001b[1;32m    428\u001b[0m     download_func,\n\u001b[1;32m    429\u001b[0m     url_or_urls,\n\u001b[1;32m    430\u001b[0m     map_tuple\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    431\u001b[0m     num_proc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mnum_proc,\n\u001b[1;32m    432\u001b[0m     disable_tqdm\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m is_progress_bar_enabled(),\n\u001b[1;32m    433\u001b[0m     desc\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDownloading data files\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    434\u001b[0m )\n\u001b[1;32m    435\u001b[0m duration \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m    436\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading took \u001b[39m\u001b[39m{\u001b[39;00mduration\u001b[39m.\u001b[39mtotal_seconds()\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39m\u001b[39m60\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m min\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/utils/py_utils.py:443\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    441\u001b[0m     num_proc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(iterable) \u001b[39m<\u001b[39m parallel_min_length:\n\u001b[0;32m--> 443\u001b[0m     mapped \u001b[39m=\u001b[39m [\n\u001b[1;32m    444\u001b[0m         _single_map_nested((function, obj, types, \u001b[39mNone\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m))\n\u001b[1;32m    445\u001b[0m         \u001b[39mfor\u001b[39;49;00m obj \u001b[39min\u001b[39;49;00m logging\u001b[39m.\u001b[39;49mtqdm(iterable, disable\u001b[39m=\u001b[39;49mdisable_tqdm, desc\u001b[39m=\u001b[39;49mdesc)\n\u001b[1;32m    446\u001b[0m     ]\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     num_proc \u001b[39m=\u001b[39m num_proc \u001b[39mif\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(iterable) \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(iterable)\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/utils/py_utils.py:444\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    441\u001b[0m     num_proc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(iterable) \u001b[39m<\u001b[39m parallel_min_length:\n\u001b[1;32m    443\u001b[0m     mapped \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 444\u001b[0m         _single_map_nested((function, obj, types, \u001b[39mNone\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m))\n\u001b[1;32m    445\u001b[0m         \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(iterable, disable\u001b[39m=\u001b[39mdisable_tqdm, desc\u001b[39m=\u001b[39mdesc)\n\u001b[1;32m    446\u001b[0m     ]\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     num_proc \u001b[39m=\u001b[39m num_proc \u001b[39mif\u001b[39;00m num_proc \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(iterable) \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(iterable)\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/utils/py_utils.py:363\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[39mreturn\u001b[39;00m {k: _single_map_nested((function, v, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m pbar}\n\u001b[1;32m    362\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m     mapped \u001b[39m=\u001b[39m [_single_map_nested((function, v, types, \u001b[39mNone\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)) \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m pbar]\n\u001b[1;32m    364\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    365\u001b[0m         \u001b[39mreturn\u001b[39;00m mapped\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/utils/py_utils.py:363\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[39mreturn\u001b[39;00m {k: _single_map_nested((function, v, types, \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m pbar}\n\u001b[1;32m    362\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m     mapped \u001b[39m=\u001b[39m [_single_map_nested((function, v, types, \u001b[39mNone\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m pbar]\n\u001b[1;32m    364\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    365\u001b[0m         \u001b[39mreturn\u001b[39;00m mapped\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/utils/py_utils.py:346\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39m# Singleton first to spare some computation\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_struct, types):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    348\u001b[0m \u001b[39m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m logging\u001b[39m.\u001b[39mget_verbosity() \u001b[39m<\u001b[39m logging\u001b[39m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/download/download_manager.py:453\u001b[0m, in \u001b[0;36mDownloadManager._download\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[1;32m    451\u001b[0m     \u001b[39m# append the relative path to the base_path\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     url_or_filename \u001b[39m=\u001b[39m url_or_path_join(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_path, url_or_filename)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m cached_path(url_or_filename, download_config\u001b[39m=\u001b[39;49mdownload_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/utils/file_utils.py:183\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     url_or_filename \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(url_or_filename)\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    182\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m    184\u001b[0m         url_or_filename,\n\u001b[1;32m    185\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    186\u001b[0m         force_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mforce_download,\n\u001b[1;32m    187\u001b[0m         proxies\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    188\u001b[0m         resume_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mresume_download,\n\u001b[1;32m    189\u001b[0m         user_agent\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muser_agent,\n\u001b[1;32m    190\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mlocal_files_only,\n\u001b[1;32m    191\u001b[0m         use_etag\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_etag,\n\u001b[1;32m    192\u001b[0m         max_retries\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    193\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_auth_token,\n\u001b[1;32m    194\u001b[0m         ignore_url_params\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mignore_url_params,\n\u001b[1;32m    195\u001b[0m         storage_options\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[1;32m    196\u001b[0m         download_desc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mdownload_desc,\n\u001b[1;32m    197\u001b[0m     )\n\u001b[1;32m    198\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    199\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/utils/file_utils.py:611\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, use_auth_token, ignore_url_params, storage_options, download_desc)\u001b[0m\n\u001b[1;32m    609\u001b[0m         fsspec_get(url, temp_file, storage_options\u001b[39m=\u001b[39mstorage_options, desc\u001b[39m=\u001b[39mdownload_desc)\n\u001b[1;32m    610\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 611\u001b[0m         http_get(\n\u001b[1;32m    612\u001b[0m             url,\n\u001b[1;32m    613\u001b[0m             temp_file,\n\u001b[1;32m    614\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    615\u001b[0m             resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[1;32m    616\u001b[0m             headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    617\u001b[0m             cookies\u001b[39m=\u001b[39;49mcookies,\n\u001b[1;32m    618\u001b[0m             max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[1;32m    619\u001b[0m             desc\u001b[39m=\u001b[39;49mdownload_desc,\n\u001b[1;32m    620\u001b[0m         )\n\u001b[1;32m    622\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mcache_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    623\u001b[0m shutil\u001b[39m.\u001b[39mmove(temp_file\u001b[39m.\u001b[39mname, cache_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/site-packages/datasets/utils/file_utils.py:405\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, cookies, timeout, max_retries, desc)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[1;32m    404\u001b[0m     progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n\u001b[0;32m--> 405\u001b[0m     temp_file\u001b[39m.\u001b[39;49mwrite(chunk)\n",
      "File \u001b[0;32m~/miniconda3/envs/semantic-memorization/lib/python3.11/tempfile.py:483\u001b[0m, in \u001b[0;36m_TemporaryFileWrapper.__getattr__.<locals>.func_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39m@_functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    482\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_wrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 483\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pile_tokens = load_dataset(\"EleutherAI/pile-deduped-pythia-random-sampled\").to_pandas()\n",
    "pile_tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-memorization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
